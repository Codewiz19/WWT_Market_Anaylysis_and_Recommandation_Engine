{"cells":[{"cell_type":"markdown","source":["##1 Installing Required Libraries\n","This step ensures that all necessary Python packages are available for the notebook.\n","\n","gensim → Provides tools for topic modeling, word embeddings, and other natural language processing (NLP) tasks.\n","\n","pandas → A versatile data manipulation library for handling datasets in tabular form.\n","\n","scikit-learn → Offers a wide range of machine learning algorithms, along with utilities for preprocessing, model selection, and evaluation."],"metadata":{"id":"SasDQKOWN0Hy"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":829},"id":"W1y1VaFok0LZ","outputId":"f3b7ebff-a381-4404-b28f-158cddddf08f","executionInfo":{"status":"ok","timestamp":1754935856148,"user_tz":-330,"elapsed":24693,"user":{"displayName":"Abhishek Patil","userId":"16421709600748109372"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gensim\n","  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Collecting numpy<2.0,>=1.18.5 (from gensim)\n","  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n","  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0.post1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n","Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.16.1\n","    Uninstalling scipy-1.16.1:\n","      Successfully uninstalled scipy-1.16.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"c304e6922fd546d89b069d5a069f28a9"}},"metadata":{}}],"source":["!pip install gensim pandas   scikit-learn"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"WG_YaYMLk3f4","executionInfo":{"status":"ok","timestamp":1754935891259,"user_tz":-330,"elapsed":10027,"user":{"displayName":"Abhishek Patil","userId":"16421709600748109372"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import json\n","import ast # To safely evaluate string representation of list\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pandas as pd\n","from sklearn.preprocessing import OneHotEncoder\n","from scipy.sparse import hstack\n","\n","import pandas as pd\n","from sklearn.feature_extraction import DictVectorizer\n","import torch\n","\n","\n","from gensim.models import Word2Vec\n","from google.colab import drive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hLUYMl9-ekfS","outputId":"afc09235-67e2-432f-daab-d748d607cd42"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":["# Set device to GPU if available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f'Using device: {device}')"]},{"cell_type":"markdown","metadata":{"id":"1U141fUnekfT"},"source":["\n","\n","## 2. Fixing Broken CSV Rows with Unbalanced Quotes\n","\n","In this step:\n","\n","The script reads the raw CSV (order_data.csv) line-by-line, buffering text until it detects a balanced number of quotes (\") in the current chunk.\n","\n","If the number of quotes is even, it means the row is complete and safe to write to the cleaned file.\n","\n","If quotes are still unbalanced (odd count), the script keeps appending subsequent lines until the row is closed properly.\n","\n","The result is a new, cleaned CSV (order_data_cleaned.csv) where each row is structurally intact—preventing parsing issues in pandas or other tools downstream."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_DlpfDRoE1pe","outputId":"c460fe48-ee4b-4c60-e316-e91409d4779d","executionInfo":{"status":"ok","timestamp":1754936075070,"user_tz":-330,"elapsed":9538,"user":{"displayName":"Abhishek Patil","userId":"16421709600748109372"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Cleaned file saved to: /content/drive/MyDrive/Colab Notebooks/WWT Hackathon/content/Dataset/order_data_cleaned.csv\n"]}],"source":["import os\n","\n","input_file = '/content/drive/MyDrive/Colab Notebooks/WWT Hackathon/content/Dataset/order_data.csv'\n","output_file = '/content/drive/MyDrive/Colab Notebooks/WWT Hackathon/content/Dataset/order_data_cleaned.csv'\n","\n","# Check if the input file exists\n","if not os.path.exists(input_file):\n","    print(f\"Error: Input file not found at {input_file}\")\n","else:\n","    with open(input_file, 'r', encoding='utf-8', errors='ignore') as infile, \\\n","         open(output_file, 'w', encoding='utf-8') as outfile:\n","\n","        quote_open = False\n","        buffer = ''\n","\n","        for line in infile:\n","            buffer += line\n","\n","            # Count quotes in the buffer to see if it's complete\n","            quote_count = buffer.count('\"')\n","\n","            if quote_count % 2 == 0:\n","                outfile.write(buffer)\n","                buffer = ''  # reset buffer\n","            else:\n","                buffer += '\\n'  # continue reading to complete the line\n","\n","    print(\"✅ Cleaned file saved to:\", output_file)"]},{"cell_type":"markdown","source":["## 3. Data Loading and Preparation\n","\n","This section reuses the robust data cleaning pipeline from our EDA to create the Analytical Base Table (ABT). We then encode all categorical features into unique numerical IDs, which are required for the model's embedding layers."],"metadata":{"id":"pEPomHeWOflD"}},{"cell_type":"code","execution_count":7,"metadata":{"id":"2aNqToQ9ekfT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754936087550,"user_tz":-330,"elapsed":11260,"user":{"displayName":"Abhishek Patil","userId":"16421709600748109372"}},"outputId":"276a341b-589c-45ee-abd7-9a136ef9d770"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["\n","# 1) Mount Google Drive\n","drive.mount('/content/drive')\n","# --- 1. Load Data ---\n","file_path = '/content/drive/MyDrive/Colab Notebooks/WWT Hackathon/content/Dataset/'\n","order_data = pd.read_csv(file_path + 'order_data_cleaned.csv', on_bad_lines='skip')\n","customer_data = pd.read_csv(file_path + 'customer_data.csv')\n","store_data = pd.read_csv(file_path +'store_data_full.csv')\n","test_question_data = pd.read_csv(file_path + 'test_data_question.csv')\n","\n"]},{"cell_type":"markdown","source":["## 4. Combining Orders with Store and Customer Information\n","\n","Raw order records by themselves often lack the full context needed for analysis. Here, we progressively merge datasets to create a unified view:  \n","\n","1. **Orders ↔ Store Data** (`STORE_NUMBER` as key)  \n","   - Enriches each order with store-level attributes such as location, region, or store type.  \n","   - `how='left'` ensures that all orders are retained, even if some store details are missing.  \n","\n","2. **(Orders + Store) ↔ Customer Data** (`CUSTOMER_ID` as key)  \n","   - Adds demographic or behavioral attributes for each customer, enabling more nuanced analysis.  \n","   - Again, a left join is used so that every order from the first merge remains in the dataset.  \n","\n","The resulting `final_merged_data` becomes the **master dataset**—a single, feature-rich table that will drive the rest of the preprocessing, feature engineering, and modeling steps.\n"],"metadata":{"id":"-Jc68RAROpa8"}},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OmpDIcWrlHjZ","outputId":"c5d4c10a-7a58-4c8d-e3fb-91cbe930488f","executionInfo":{"status":"ok","timestamp":1754936088118,"user_tz":-330,"elapsed":563,"user":{"displayName":"Abhishek Patil","userId":"16421709600748109372"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["(1048575, 10)\n"]}],"source":["# Merge order_data with store_data on 'STORE_NUMBER'\n","merged_data = pd.merge(order_data, store_data, on='STORE_NUMBER', how='left')\n","\n","# Merge the result with customer_data on 'CUSTOMER_ID'\n","final_merged_data = pd.merge(merged_data, customer_data, on='CUSTOMER_ID', how='left')\n","final_merged_data.head()\n","print(final_merged_data.shape)\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kobB2ZTolTJz","outputId":"cec3d519-d36d-4eee-b5f2-6c76f30242bb","executionInfo":{"status":"ok","timestamp":1754936089659,"user_tz":-330,"elapsed":1538,"user":{"displayName":"Abhishek Patil","userId":"16421709600748109372"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["(1012935, 10)\n"]}],"source":["# Load the merged dataset\n","df = final_merged_data\n","# Remove rows with any null values\n","cleaned_df = df.dropna()\n","# Assuming your cleaned DataFrame is named cleaned_df\n","shape = cleaned_df.shape\n","print(shape)"]},{"cell_type":"markdown","source":["##6. Extracting Relevant Food Items from Order Data\n","\n","Order records often include both actual menu items and system-generated entries (e.g., fees, tips, delivery charges).  \n","This step focuses on **isolating true food items** by:  \n","\n","- Defining a list of `system_keywords` that mark non-food entries to exclude.  \n","- Parsing the JSON structure in the `ORDERS` column to locate `item_details`.  \n","- Skipping:\n","  - Items with `item_price = 0` (free or placeholder entries).  \n","  - Items whose names contain any of the system keywords (case-insensitive match).  \n","- Returning a clean list of only the purchased food item names for each order.  \n","\n","The function `extract_food_items()` is applied to every row in the dataset to populate a new `extracted_items` column, which will be useful for later steps like:\n","- Menu trend analysis  \n","- Recommendation systems  \n","- Word embedding training for food item names  \n"],"metadata":{"id":"OQnTF5rWPmOl"}},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hvG5dhhElV0i","outputId":"4c6e3ab4-0ba9-4131-8861-eb0619bddaec","executionInfo":{"status":"ok","timestamp":1754936098883,"user_tz":-330,"elapsed":9210,"user":{"displayName":"Abhishek Patil","userId":"16421709600748109372"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["   CUSTOMER_ID  STORE_NUMBER ORDER_CREATED_DATE    ORDER_ID  \\\n","0    362204699          2156         24-07-2024  7247194287   \n","1    269612955          1419         15-02-2025   791214421   \n","2    585330633          2249         15-02-2025  7575285208   \n","3    950661333          2513         29-03-2024  4253875716   \n","4    434985772          1754         08-04-2024  7150407872   \n","\n","                                              ORDERS ORDER_CHANNEL_NAME  \\\n","0  {\"orders\": [{\"item_details\": [{\"item_name\": \"O...            Digital   \n","1  {\"orders\": [{\"item_details\": [{\"item_name\": \"R...            Digital   \n","2  {\"orders\": [{\"item_details\": [{\"item_name\": \"2...            Digital   \n","3  {\"orders\": [{\"item_details\": [{\"item_name\": \"O...            Digital   \n","4  {\"orders\": [{\"item_details\": [{\"item_name\": \"O...            Digital   \n","\n","  ORDER_SUBCHANNEL_NAME ORDER_OCCASION_NAME      CITY_FILLED CUSTOMER_TYPE  \\\n","0                   WWT                ToGo        GRAPEVINE    Registered   \n","1                   WWT                ToGo     HUNTERSVILLE    Registered   \n","2                   WWT                ToGo  Winter Park, FL         Guest   \n","3                   WWT                ToGo        LAS VEGAS    Registered   \n","4                   WWT                ToGo          ARDMORE         Guest   \n","\n","                                     extracted_items  \n","0  [10 pc Grilled Wings Combo, 8 pc Grilled Wings...  \n","1  [Ranch Dip - Regular, 50 pc Grilled Wings, Reg...  \n","2                            [20pc Spicy Feast Deal]  \n","3         [20 pc Grilled Wings, Ranch Dip - Regular]  \n","4  [6 pc Grilled Wings Combo, 8 pc Grilled Wings ...  \n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-454583920.py:43: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df['extracted_items'] = df['ORDERS'].apply(extract_food_items)\n"]}],"source":["# Define the keywords to be excluded\n","system_keywords = [\n","    'tip', 'fee', 'bag', 'delivery', 'service', 'charge',\n","    'memo', 'blankline', 'asap', 'paid', 'subtotal', 'tax'\n","]\n","\n","def extract_food_items(orders_json_string):\n","    \"\"\"\n","    Parses the JSON string from the 'ORDERS' column, filters out non-food items,\n","    and returns a list of food item names.\n","    \"\"\"\n","    if not isinstance(orders_json_string, str):\n","        return []\n","\n","    try:\n","        data = json.loads(orders_json_string)\n","        if 'orders' not in data or not data['orders'] or 'item_details' not in data['orders'][0]:\n","             return []\n","\n","        item_details = data['orders'][0]['item_details']\n","        food_items = []\n","\n","        for item in item_details:\n","            if item.get('item_price', 0) == 0:\n","                continue\n","\n","            item_name_lower = item.get('item_name', '').lower()\n","            if any(keyword in item_name_lower for keyword in system_keywords):\n","                continue\n","\n","            food_items.append(item['item_name'])\n","\n","        return food_items\n","\n","    except (json.JSONDecodeError, TypeError, KeyError):\n","        return []\n","\n","# Load the previously cleaned data\n","\n","df = cleaned_df # Modified line\n","\n","# Apply the function to create the new 'extracted_items' column\n","df['extracted_items'] = df['ORDERS'].apply(extract_food_items)\n","\n","# Save the result to a new CSV file\n","# df.to_csv('final_data_with_items.csv', index=False)\n","\n","# Display the relevant columns of the resulting DataFrame\n","print(df.head())"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xVihxbe_lXK3","outputId":"9698c02c-141d-4d9c-e17b-2a9c65af262c","executionInfo":{"status":"ok","timestamp":1754936104909,"user_tz":-330,"elapsed":6031,"user":{"displayName":"Abhishek Patil","userId":"16421709600748109372"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Columns before removal:\n","Index(['CUSTOMER_ID', 'STORE_NUMBER', 'ORDER_CREATED_DATE', 'ORDER_ID',\n","       'ORDERS', 'ORDER_CHANNEL_NAME', 'ORDER_SUBCHANNEL_NAME',\n","       'ORDER_OCCASION_NAME', 'CITY_FILLED', 'CUSTOMER_TYPE',\n","       'extracted_items'],\n","      dtype='object')\n","\n","Columns after removal:\n","Index(['CUSTOMER_ID', 'STORE_NUMBER', 'ORDER_CREATED_DATE', 'ORDER_ID',\n","       'ORDER_CHANNEL_NAME', 'ORDER_SUBCHANNEL_NAME', 'ORDER_OCCASION_NAME',\n","       'CITY_FILLED', 'CUSTOMER_TYPE', 'extracted_items'],\n","      dtype='object')\n","         CUSTOMER_ID  STORE_NUMBER ORDER_CREATED_DATE    ORDER_ID  \\\n","0          362204699          2156         24-07-2024  7247194287   \n","1          269612955          1419         15-02-2025   791214421   \n","2          585330633          2249         15-02-2025  7575285208   \n","3          950661333          2513         29-03-2024  4253875716   \n","4          434985772          1754         08-04-2024  7150407872   \n","...              ...           ...                ...         ...   \n","1048570    991507396          4094         24-02-2025   278450715   \n","1048571    991507396          4094         22-01-2025  5021306418   \n","1048572    991507396          4094         25-03-2025  4131451329   \n","1048573    991507396          4094         25-08-2024  8875040363   \n","1048574    729600859          4595         29-10-2024  3480530584   \n","\n","        ORDER_CHANNEL_NAME ORDER_SUBCHANNEL_NAME ORDER_OCCASION_NAME  \\\n","0                  Digital                   WWT                ToGo   \n","1                  Digital                   WWT                ToGo   \n","2                  Digital                   WWT                ToGo   \n","3                  Digital                   WWT                ToGo   \n","4                  Digital                   WWT                ToGo   \n","...                    ...                   ...                 ...   \n","1048570            Digital                   WWT                ToGo   \n","1048571            Digital                   WWT                ToGo   \n","1048572            Digital                   WWT                ToGo   \n","1048573            Digital                   WWT                ToGo   \n","1048574            Digital                   WWT                ToGo   \n","\n","             CITY_FILLED CUSTOMER_TYPE  \\\n","0              GRAPEVINE    Registered   \n","1           HUNTERSVILLE    Registered   \n","2        Winter Park, FL         Guest   \n","3              LAS VEGAS    Registered   \n","4                ARDMORE         Guest   \n","...                  ...           ...   \n","1048570      SAN ANTONIO    Registered   \n","1048571      SAN ANTONIO    Registered   \n","1048572      SAN ANTONIO    Registered   \n","1048573      SAN ANTONIO    Registered   \n","1048574        CHARLOTTE         Guest   \n","\n","                                           extracted_items  \n","0        [10 pc Grilled Wings Combo, 8 pc Grilled Wings...  \n","1        [Ranch Dip - Regular, 50 pc Grilled Wings, Reg...  \n","2                                  [20pc Spicy Feast Deal]  \n","3               [20 pc Grilled Wings, Ranch Dip - Regular]  \n","4        [6 pc Grilled Wings Combo, 8 pc Grilled Wings ...  \n","...                                                    ...  \n","1048570  [Regular Buffalo Fries, Veggie Sticks Spicy, R...  \n","1048571  [Ranch Dip - Regular, Fried Corn - Regular, Ve...  \n","1048572       [20pc Spicy Feast Deal, Ranch Dip - Regular]  \n","1048573  [6 pc Spicy Wings Combo, 6 pc Grilled Wings Co...  \n","1048574  [6 pc Spicy Wings Combo, 10 pc Spicy Wings Combo]  \n","\n","[1012935 rows x 10 columns]\n"]}],"source":["# # Load the dataset\n","# df = pd.read_csv('final_data_with_items.csv')\n","\n","print(\"Columns before removal:\")\n","print(df.columns)\n","\n","# Remove the 'ORDERS' column\n","df_no_orders = df.drop('ORDERS', axis=1)\n","\n","print(\"\\nColumns after removal:\")\n","print(df_no_orders.columns)\n","\n","\n","print(df_no_orders )\n","df_no_orders.to_csv('final_data.csv', index=False)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"RH9zRamQl58h","executionInfo":{"status":"ok","timestamp":1754936106412,"user_tz":-330,"elapsed":1499,"user":{"displayName":"Abhishek Patil","userId":"16421709600748109372"}}},"outputs":[],"source":["# Load the cleaned data\n","df = pd.read_csv('final_data.csv')"]},{"cell_type":"markdown","source":["##7. Analyzing Item Counts and Menu Diversity\n","\n","After extracting clean food item names, this step performs **basic descriptive statistics** to understand order size patterns and menu variety:  \n","\n","1. **Convert String to List**  \n","   - The `extracted_items` column (currently stored as a string) is converted back into an actual Python list using `ast.literal_eval` for safe evaluation.  \n","\n","2. **Order Size Statistics**  \n","   - `item_count`: Number of items in each order.  \n","   - `max_items`, `min_items`, `median_items`: Key metrics showing the largest, smallest, and median order sizes.  \n","   - These figures can help identify extreme orders, typical purchasing patterns, and operational considerations for fulfillment.  \n","\n","3. **Menu Diversity**  \n","   - Combines all extracted item lists into one flat list (`all_items`).  \n","   - Calculates `num_unique_items` by converting to a `set`, revealing how many distinct food items are present across all orders.  \n","   - Useful for understanding menu breadth, designing recommendation systems, and guiding stock/inventory planning.  \n"],"metadata":{"id":"YDLrmQ3rPz-2"}},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nY408W8ymB7U","outputId":"57398943-46cb-4bd6-96f9-37ced139941d","executionInfo":{"status":"ok","timestamp":1754936117896,"user_tz":-330,"elapsed":11475,"user":{"displayName":"Abhishek Patil","userId":"16421709600748109372"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Maximum number of items in a single order: 15\n","Minimum number of items in a single order: 0\n","Median number of items per order: 2.0\n","Total number of unique items across all orders: 128\n"]}],"source":["# Convert the string representation of a list back into a list object\n","df['extracted_items_list'] = df['extracted_items'].apply(ast.literal_eval)\n","\n","# --- 1, 2, 3: Calculate Max, Min, and Median number of items ---\n","\n","# Get the number of items in each order\n","df['item_count'] = df['extracted_items_list'].apply(len)\n","\n","# Calculate the stats\n","max_items = df['item_count'].max()\n","min_items = df['item_count'].min()\n","median_items = df['item_count'].median()\n","\n","print(f\"Maximum number of items in a single order: {max_items}\")\n","print(f\"Minimum number of items in a single order: {min_items}\")\n","print(f\"Median number of items per order: {median_items}\")\n","\n","\n","# --- 4: Calculate the number of unique items ---\n","\n","# Create a single list of all items from all orders\n","all_items = [item for sublist in df['extracted_items_list'] for item in sublist]\n","\n","# Find the unique items using a set\n","num_unique_items = len(set(all_items))\n","\n","print(f\"Total number of unique items across all orders: {num_unique_items}\")"]},{"cell_type":"markdown","source":["## 8. Filtering Out Small or Empty Orders\n","\n","Not all orders are equally useful for downstream analysis.  \n","This step removes orders that contain too few items to provide meaningful insights:  \n","\n","1. **Item Count Calculation**  \n","   - Recomputes `item_count` as the length of each `extracted_items_list`.  \n","\n","2. **Filtering Criteria**  \n","   - Keeps only rows where `item_count > 1`.  \n","   - This excludes:\n","     - Empty orders (possible data errors)  \n","     - Single-item orders (less informative for co-occurrence or recommendation modeling).  \n","\n","3. **Result**  \n","   - `df_filtered` becomes the refined dataset, containing only orders with a richer set of items, making it more suitable for analyses such as:\n","     - Association rule mining  \n","     - Basket analysis  \n","     - Menu combination patterns  \n"],"metadata":{"id":"t6SNmS0HP_-U"}},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nY3v3-gimLdq","outputId":"7eab4a44-7a8a-41da-8210-7cc88ddccd3d","executionInfo":{"status":"ok","timestamp":1754936118420,"user_tz":-330,"elapsed":502,"user":{"displayName":"Abhishek Patil","userId":"16421709600748109372"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["         CUSTOMER_ID  STORE_NUMBER ORDER_CREATED_DATE    ORDER_ID  \\\n","0          362204699          2156         24-07-2024  7247194287   \n","1          269612955          1419         15-02-2025   791214421   \n","3          950661333          2513         29-03-2024  4253875716   \n","4          434985772          1754         08-04-2024  7150407872   \n","6          426992703          2156         15-02-2025  1655782790   \n","...              ...           ...                ...         ...   \n","1012930    991507396          4094         24-02-2025   278450715   \n","1012931    991507396          4094         22-01-2025  5021306418   \n","1012932    991507396          4094         25-03-2025  4131451329   \n","1012933    991507396          4094         25-08-2024  8875040363   \n","1012934    729600859          4595         29-10-2024  3480530584   \n","\n","        ORDER_CHANNEL_NAME ORDER_SUBCHANNEL_NAME ORDER_OCCASION_NAME  \\\n","0                  Digital                   WWT                ToGo   \n","1                  Digital                   WWT                ToGo   \n","3                  Digital                   WWT                ToGo   \n","4                  Digital                   WWT                ToGo   \n","6                  Digital                   WWT                ToGo   \n","...                    ...                   ...                 ...   \n","1012930            Digital                   WWT                ToGo   \n","1012931            Digital                   WWT                ToGo   \n","1012932            Digital                   WWT                ToGo   \n","1012933            Digital                   WWT                ToGo   \n","1012934            Digital                   WWT                ToGo   \n","\n","          CITY_FILLED CUSTOMER_TYPE  \\\n","0           GRAPEVINE    Registered   \n","1        HUNTERSVILLE    Registered   \n","3           LAS VEGAS    Registered   \n","4             ARDMORE         Guest   \n","6           GRAPEVINE         Guest   \n","...               ...           ...   \n","1012930   SAN ANTONIO    Registered   \n","1012931   SAN ANTONIO    Registered   \n","1012932   SAN ANTONIO    Registered   \n","1012933   SAN ANTONIO    Registered   \n","1012934     CHARLOTTE         Guest   \n","\n","                                           extracted_items  \\\n","0        ['10 pc Grilled Wings Combo', '8 pc Grilled Wi...   \n","1        ['Ranch Dip - Regular', '50 pc Grilled Wings',...   \n","3           ['20 pc Grilled Wings', 'Ranch Dip - Regular']   \n","4        ['6 pc Grilled Wings Combo', '8 pc Grilled Win...   \n","6           ['10 pc Grilled Wings', 'Ranch Dip - Regular']   \n","...                                                    ...   \n","1012930  ['Regular Buffalo Fries', 'Veggie Sticks Spicy...   \n","1012931  ['Ranch Dip - Regular', 'Fried Corn - Regular'...   \n","1012932   ['20pc Spicy Feast Deal', 'Ranch Dip - Regular']   \n","1012933  ['6 pc Spicy Wings Combo', '6 pc Grilled Wings...   \n","1012934  ['6 pc Spicy Wings Combo', '10 pc Spicy Wings ...   \n","\n","                                      extracted_items_list  item_count  \n","0        [10 pc Grilled Wings Combo, 8 pc Grilled Wings...           3  \n","1        [Ranch Dip - Regular, 50 pc Grilled Wings, Reg...           3  \n","3               [20 pc Grilled Wings, Ranch Dip - Regular]           2  \n","4        [6 pc Grilled Wings Combo, 8 pc Grilled Wings ...           2  \n","6               [10 pc Grilled Wings, Ranch Dip - Regular]           2  \n","...                                                    ...         ...  \n","1012930  [Regular Buffalo Fries, Veggie Sticks Spicy, R...           5  \n","1012931  [Ranch Dip - Regular, Fried Corn - Regular, Ve...           4  \n","1012932       [20pc Spicy Feast Deal, Ranch Dip - Regular]           2  \n","1012933  [6 pc Spicy Wings Combo, 6 pc Grilled Wings Co...           2  \n","1012934  [6 pc Spicy Wings Combo, 10 pc Spicy Wings Combo]           2  \n","\n","[578791 rows x 12 columns]\n","(578791, 12)\n"]}],"source":["# First, create a column that holds the number of items in each list.\n","df['item_count'] = df['extracted_items_list'].apply(len)\n","\n","# Now, filter the DataFrame, keeping only rows where 'item_count' is not 0.\n","df_filtered = df[df['item_count'] > 1].copy()\n","\n","# 'df_filtered' now contains only the entries with one or more items.\n","# You can display it by uncommenting the line below:\n","print(df_filtered )\n","print(df_filtered.shape )"]},{"cell_type":"markdown","source":["## 9. Identifying Repeat Customers  \n","\n","Understanding repeat customer behavior is important for loyalty analysis and targeted marketing.  \n","This step identifies customers who appear in the dataset more than once:  \n","\n","1. **Frequency Count**  \n","   - Uses `value_counts()` on the `CUSTOMER_ID` column to determine how many orders each customer has placed.  \n","\n","2. **Filtering for Repeat Customers**  \n","   - Keeps only entries where the count is greater than 1.  \n","\n","3. **Output**  \n","   - Displays a list of `CUSTOMER_ID`s and their corresponding order counts if repeats exist.  \n","   - If no repeat customers are found, it prints a clear message instead.  \n"],"metadata":{"id":"ne7H2Mw-QOHC"}},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zlhW7lmFmNcx","outputId":"47f77635-647b-484d-dce5-ed4eff8f0acc","executionInfo":{"status":"ok","timestamp":1754936118537,"user_tz":-330,"elapsed":110,"user":{"displayName":"Abhishek Patil","userId":"16421709600748109372"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Frequency of Repeated Customer IDs:\n","CUSTOMER_ID\n","522408835    1273\n","575231786     150\n","807861401     107\n","963730416      86\n","755237459      84\n","             ... \n","190416050       2\n","58477150        2\n","339995743       2\n","290442816       2\n","111140082       2\n","Name: count, Length: 87447, dtype: int64\n"]}],"source":["df = df_filtered\n","\n","\n","# Get the frequency count of each CUSTOMER_ID\n","customer_frequency = df['CUSTOMER_ID'].value_counts()\n","\n","# Filter to find only the customers who have appeared more than once\n","repeated_customers = customer_frequency[customer_frequency > 1]\n","\n","# Display the result\n","if repeated_customers.empty:\n","    print(\"No repeated customer IDs found in the data.\")\n","else:\n","    print(\"Frequency of Repeated Customer IDs:\")\n","    print(repeated_customers)"]},{"cell_type":"markdown","source":["## 10. Visualizing Repeat Customer Order Frequency\n","\n","After identifying repeat customers, this step examines how frequently they place orders within a reasonable range:  \n","\n","1. **Filtering Frequency Range**  \n","   - Keeps only customers with **1–150 orders**.  \n","   - This removes extreme outliers that could distort the visualization (e.g., system test accounts or bulk buyers).  \n","\n","2. **Distribution Plot**  \n","   - Uses `seaborn.histplot` to show how many customers fall into each order-count bucket.  \n","   - **X-axis:** Number of orders per customer.  \n","   - **Y-axis:** Number of customers with that order count.  \n","\n","3. **Purpose**  \n","   - Helps understand purchasing behavior patterns.  \n","   - Can guide loyalty program thresholds, targeted campaigns, and operational forecasting.  \n"],"metadata":{"id":"kQXPdNi1QUUm"}},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":641},"id":"6FHwsXRJmQAc","outputId":"589141c8-98cb-4722-8972-85c874265195","executionInfo":{"status":"ok","timestamp":1754936119100,"user_tz":-330,"elapsed":559,"user":{"displayName":"Abhishek Patil","userId":"16421709600748109372"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1500x700 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["# Filter the repeated_customers Series for frequencies between 0 and 150\n","repeated_customers_filtered = repeated_customers[(repeated_customers > 0) & (repeated_customers <= 150)]\n","\n","# Create a bar plot\n","plt.figure(figsize=(15, 7))\n","sns.histplot(repeated_customers_filtered, bins=150, kde=False) # Using histplot to show distribution of frequencies\n","plt.title('Frequency of Repeated Customer IDs (0 to 150)')\n","plt.xlabel('Number of Orders per Customer')\n","plt.ylabel('Number of Customers')\n","plt.grid(axis='y', alpha=0.75)\n","plt.show()"]},{"cell_type":"markdown","source":["## 11. Splitting Customers by Purchase Frequency  \n","\n","To better segment the customer base, this step separates customers into two distinct groups based on their order frequency:  \n","\n","1. **Count Orders per Customer**  \n","   - Uses `value_counts()` to compute how many orders each `CUSTOMER_ID` has placed.  \n","\n","2. **Define High-Frequency Customers**  \n","   - Customers with **more than 2 orders** are classified as repeat-heavy customers.  \n","\n","3. **DataFrame Segmentation**  \n","   - **`df_repeated_more_than_2`** → Orders from high-frequency customers (> 2 orders).  \n","   - **`df_others`** → Orders from all remaining customers (1–2 orders).  \n","\n","4. **Purpose**  \n","   - Enables targeted analysis and personalized marketing.  \n","   - High-frequency customers can be prioritized for retention strategies, while others may be targeted for re-engagement campaigns.  \n"],"metadata":{"id":"YaB18_a-QhWi"}},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rn3YbMwdmTEf","outputId":"d0afdf67-9cff-446b-e147-0fb8cdf79e1f","executionInfo":{"status":"ok","timestamp":1754936119169,"user_tz":-330,"elapsed":64,"user":{"displayName":"Abhishek Patil","userId":"16421709600748109372"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["--- DataFrame 1: Customers Repeated More Than 2 Times ---\n","         CUSTOMER_ID  STORE_NUMBER ORDER_CREATED_DATE    ORDER_ID  \\\n","321441       5390549          4391         24-02-2025  6442283098   \n","321442       5390549          4391         31-07-2024   804028356   \n","321444       5390549          4391         25-04-2025  5755222216   \n","321445       5390549          4391         08-01-2025  9601434771   \n","321446       5390549          4391         18-04-2024  1229377604   \n","...              ...           ...                ...         ...   \n","1012928    991507396          4094         08-01-2025  8381642281   \n","1012930    991507396          4094         24-02-2025   278450715   \n","1012931    991507396          4094         22-01-2025  5021306418   \n","1012932    991507396          4094         25-03-2025  4131451329   \n","1012933    991507396          4094         25-08-2024  8875040363   \n","\n","        ORDER_CHANNEL_NAME ORDER_SUBCHANNEL_NAME ORDER_OCCASION_NAME  \\\n","321441             Digital                   WWT                ToGo   \n","321442             Digital                   WWT                ToGo   \n","321444             Digital                   WWT                ToGo   \n","321445             Digital                   WWT                ToGo   \n","321446             Digital                   WWT                ToGo   \n","...                    ...                   ...                 ...   \n","1012928            Digital                   WWT                ToGo   \n","1012930            Digital                   WWT                ToGo   \n","1012931            Digital                   WWT                ToGo   \n","1012932            Digital                   WWT                ToGo   \n","1012933            Digital                   WWT                ToGo   \n","\n","         CITY_FILLED CUSTOMER_TYPE  \\\n","321441         OMAHA    Registered   \n","321442         OMAHA    Registered   \n","321444         OMAHA    Registered   \n","321445         OMAHA    Registered   \n","321446         OMAHA    Registered   \n","...              ...           ...   \n","1012928  SAN ANTONIO    Registered   \n","1012930  SAN ANTONIO    Registered   \n","1012931  SAN ANTONIO    Registered   \n","1012932  SAN ANTONIO    Registered   \n","1012933  SAN ANTONIO    Registered   \n","\n","                                           extracted_items  \\\n","321441             ['32 Oz Soda', '20pc Spicy Feast Deal']   \n","321442   ['10 pc Grilled Wings Combo', '20pc Spicy Feas...   \n","321444   ['20pc Spicy Feast Deal', '10 pc Grilled Wings...   \n","321445             ['20pc Spicy Feast Deal', '20 Oz Soda']   \n","321446   ['20pc Spicy Feast Deal', 'Cheese Fries - Larg...   \n","...                                                    ...   \n","1012928  ['6 pc Grilled Wings Combo', '6 pc Spicy Wings...   \n","1012930  ['Regular Buffalo Fries', 'Veggie Sticks Spicy...   \n","1012931  ['Ranch Dip - Regular', 'Fried Corn - Regular'...   \n","1012932   ['20pc Spicy Feast Deal', 'Ranch Dip - Regular']   \n","1012933  ['6 pc Spicy Wings Combo', '6 pc Grilled Wings...   \n","\n","                                      extracted_items_list  item_count  \n","321441                 [32 Oz Soda, 20pc Spicy Feast Deal]           2  \n","321442   [10 pc Grilled Wings Combo, 20pc Spicy Feast D...           3  \n","321444   [20pc Spicy Feast Deal, 10 pc Grilled Wings Co...           2  \n","321445                 [20pc Spicy Feast Deal, 20 Oz Soda]           2  \n","321446   [20pc Spicy Feast Deal, Cheese Fries - Large, ...           4  \n","...                                                    ...         ...  \n","1012928  [6 pc Grilled Wings Combo, 6 pc Spicy Wings Co...           2  \n","1012930  [Regular Buffalo Fries, Veggie Sticks Spicy, R...           5  \n","1012931  [Ranch Dip - Regular, Fried Corn - Regular, Ve...           4  \n","1012932       [20pc Spicy Feast Deal, Ranch Dip - Regular]           2  \n","1012933  [6 pc Spicy Wings Combo, 6 pc Grilled Wings Co...           2  \n","\n","[293974 rows x 12 columns]\n","\n","=======================================================\n","\n","--- DataFrame 2: Other Customers (Appeared 1 or 2 Times) ---\n","         CUSTOMER_ID  STORE_NUMBER ORDER_CREATED_DATE    ORDER_ID  \\\n","0          362204699          2156         24-07-2024  7247194287   \n","1          269612955          1419         15-02-2025   791214421   \n","3          950661333          2513         29-03-2024  4253875716   \n","4          434985772          1754         08-04-2024  7150407872   \n","6          426992703          2156         15-02-2025  1655782790   \n","...              ...           ...                ...         ...   \n","1012886    681145112           400         05-08-2024  3037232361   \n","1012887    681145112           400         06-05-2024  8889976816   \n","1012901    980479115          2249         14-08-2024  5244667643   \n","1012902    980479115          2249         27-08-2024  7295040762   \n","1012934    729600859          4595         29-10-2024  3480530584   \n","\n","        ORDER_CHANNEL_NAME ORDER_SUBCHANNEL_NAME ORDER_OCCASION_NAME  \\\n","0                  Digital                   WWT                ToGo   \n","1                  Digital                   WWT                ToGo   \n","3                  Digital                   WWT                ToGo   \n","4                  Digital                   WWT                ToGo   \n","6                  Digital                   WWT                ToGo   \n","...                    ...                   ...                 ...   \n","1012886            Digital                   WWT                ToGo   \n","1012887            Digital                   WWT                ToGo   \n","1012901            Digital                   WWT                ToGo   \n","1012902            Digital                   WWT                ToGo   \n","1012934            Digital                   WWT                ToGo   \n","\n","             CITY_FILLED CUSTOMER_TYPE  \\\n","0              GRAPEVINE    Registered   \n","1           HUNTERSVILLE    Registered   \n","3              LAS VEGAS    Registered   \n","4                ARDMORE         Guest   \n","6              GRAPEVINE         Guest   \n","...                  ...           ...   \n","1012886          EL PASO    Registered   \n","1012887          EL PASO    Registered   \n","1012901  Winter Park, FL         Guest   \n","1012902  Winter Park, FL         Guest   \n","1012934        CHARLOTTE         Guest   \n","\n","                                           extracted_items  \\\n","0        ['10 pc Grilled Wings Combo', '8 pc Grilled Wi...   \n","1        ['Ranch Dip - Regular', '50 pc Grilled Wings',...   \n","3           ['20 pc Grilled Wings', 'Ranch Dip - Regular']   \n","4        ['6 pc Grilled Wings Combo', '8 pc Grilled Win...   \n","6           ['10 pc Grilled Wings', 'Ranch Dip - Regular']   \n","...                                                    ...   \n","1012886  ['20pc Spicy Feast Deal', 'Fried Corn - Regular']   \n","1012887  ['Add 5 Spicy Wings', '20pc Spicy Feast Deal',...   \n","1012901  ['Ranch Dip - Regular', '5 pc Crispy Strips Co...   \n","1012902  ['Ranch Dip - Regular', '5 pc Crispy Strips Co...   \n","1012934  ['6 pc Spicy Wings Combo', '10 pc Spicy Wings ...   \n","\n","                                      extracted_items_list  item_count  \n","0        [10 pc Grilled Wings Combo, 8 pc Grilled Wings...           3  \n","1        [Ranch Dip - Regular, 50 pc Grilled Wings, Reg...           3  \n","3               [20 pc Grilled Wings, Ranch Dip - Regular]           2  \n","4        [6 pc Grilled Wings Combo, 8 pc Grilled Wings ...           2  \n","6               [10 pc Grilled Wings, Ranch Dip - Regular]           2  \n","...                                                    ...         ...  \n","1012886      [20pc Spicy Feast Deal, Fried Corn - Regular]           2  \n","1012887  [Add 5 Spicy Wings, 20pc Spicy Feast Deal, Fri...           3  \n","1012901    [Ranch Dip - Regular, 5 pc Crispy Strips Combo]           2  \n","1012902    [Ranch Dip - Regular, 5 pc Crispy Strips Combo]           2  \n","1012934  [6 pc Spicy Wings Combo, 10 pc Spicy Wings Combo]           2  \n","\n","[284817 rows x 12 columns]\n"]}],"source":["# 1. Get the frequency count of each CUSTOMER_ID\n","customer_frequency = df['CUSTOMER_ID'].value_counts()\n","\n","# 2. Identify the IDs of customers who appear more than twice\n","frequent_customer_ids = customer_frequency[customer_frequency > 2].index\n","\n","# 3. Create the first DataFrame with customers appearing > 2 times\n","df_repeated_more_than_2 = df[df['CUSTOMER_ID'].isin(frequent_customer_ids)].copy()\n","\n","# 4. Create the second DataFrame with all other customers (appearing 1 or 2 times)\n","df_others = df[~df['CUSTOMER_ID'].isin(frequent_customer_ids)].copy()\n","\n","\n","# --- Display the results ---\n","\n","print(\"--- DataFrame 1: Customers Repeated More Than 2 Times ---\")\n","if df_repeated_more_than_2.empty:\n","    print(\"No customers found who appeared more than 2 times.\")\n","else:\n","    print(df_repeated_more_than_2)\n","\n","print(\"\\n\" + \"=\"*55 + \"\\n\") # Separator\n","\n","print(\"--- DataFrame 2: Other Customers (Appeared 1 or 2 Times) ---\")\n","if df_others.empty:\n","    print(\"No other customers found.\")\n","else:\n","    print(df_others)\n"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":449},"id":"khLMIsukmVLB","outputId":"48641b2d-6ca9-4819-f71d-802bf2b84d79","executionInfo":{"status":"ok","timestamp":1754936131340,"user_tz":-330,"elapsed":22,"user":{"displayName":"Abhishek Patil","userId":"16421709600748109372"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["         CUSTOMER_ID                               extracted_items_list\n","0          362204699  [10 pc Grilled Wings Combo, 8 pc Grilled Wings...\n","1          269612955  [Ranch Dip - Regular, 50 pc Grilled Wings, Reg...\n","3          950661333         [20 pc Grilled Wings, Ranch Dip - Regular]\n","4          434985772  [6 pc Grilled Wings Combo, 8 pc Grilled Wings ...\n","6          426992703         [10 pc Grilled Wings, Ranch Dip - Regular]\n","...              ...                                                ...\n","1012930    991507396  [Regular Buffalo Fries, Veggie Sticks Spicy, R...\n","1012931    991507396  [Ranch Dip - Regular, Fried Corn - Regular, Ve...\n","1012932    991507396       [20pc Spicy Feast Deal, Ranch Dip - Regular]\n","1012933    991507396  [6 pc Spicy Wings Combo, 6 pc Grilled Wings Co...\n","1012934    729600859  [6 pc Spicy Wings Combo, 10 pc Spicy Wings Combo]\n","\n","[578791 rows x 2 columns]\n"]},{"output_type":"execute_result","data":{"text/plain":["   CUSTOMER_ID                               extracted_items_list\n","0    362204699  [10 pc Grilled Wings Combo, 8 pc Grilled Wings...\n","1    269612955  [Ranch Dip - Regular, 50 pc Grilled Wings, Reg...\n","3    950661333         [20 pc Grilled Wings, Ranch Dip - Regular]\n","4    434985772  [6 pc Grilled Wings Combo, 8 pc Grilled Wings ...\n","6    426992703         [10 pc Grilled Wings, Ranch Dip - Regular]"],"text/html":["\n","  <div id=\"df-7e91e3a4-1977-428c-9f34-3a0d56c97f0d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CUSTOMER_ID</th>\n","      <th>extracted_items_list</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>362204699</td>\n","      <td>[10 pc Grilled Wings Combo, 8 pc Grilled Wings...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>269612955</td>\n","      <td>[Ranch Dip - Regular, 50 pc Grilled Wings, Reg...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>950661333</td>\n","      <td>[20 pc Grilled Wings, Ranch Dip - Regular]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>434985772</td>\n","      <td>[6 pc Grilled Wings Combo, 8 pc Grilled Wings ...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>426992703</td>\n","      <td>[10 pc Grilled Wings, Ranch Dip - Regular]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e91e3a4-1977-428c-9f34-3a0d56c97f0d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7e91e3a4-1977-428c-9f34-3a0d56c97f0d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7e91e3a4-1977-428c-9f34-3a0d56c97f0d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-cc3d8658-8678-4c1a-984e-1db7b8507605\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cc3d8658-8678-4c1a-984e-1db7b8507605')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-cc3d8658-8678-4c1a-984e-1db7b8507605 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_wordtovec"}},"metadata":{},"execution_count":18}],"source":["# Data Preparation for WordtoVec\n","# print(df_filtered )\n","\n","df_wordtovec = df_filtered[['CUSTOMER_ID', 'extracted_items_list']]\n","print(df_wordtovec )\n","df_wordtovec.head()"]},{"cell_type":"markdown","source":["## 12. Preparing Order Data for Word2Vec Training  \n","\n","Before building a Word2Vec model to learn vector representations of food items, the order data needs to be structured into training sequences:  \n","\n","1. **Extract Item Lists**  \n","   - Takes the `extracted_items_list` column from `df_wordtovec` and converts it into a list of lists (`all_orders`), where each sublist represents the items in a single order.  \n","\n","2. **Training Sentences**  \n","   - Assigns `all_orders` directly to `training_sentences`, which will be the input format expected by the Word2Vec algorithm.  \n","   - Each \"sentence\" corresponds to a basket of items, allowing the model to learn co-occurrence relationships.  \n","\n","3. **Purpose**  \n","   - Sets up the dataset so Word2Vec can capture similarities and associations between items, enabling applications like product recommendations or menu clustering.  \n"],"metadata":{"id":"Z5IA5lCuQp1c"}},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4iiLbOD5mb9I","outputId":"5101311b-f310-4237-b274-1fa858798d5a","executionInfo":{"status":"ok","timestamp":1754936133512,"user_tz":-330,"elapsed":15,"user":{"displayName":"Abhishek Patil","userId":"16421709600748109372"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Started with 578791 orders.\n","Training model on 578791 orders with more than one item. ✅\n"]}],"source":["# Extract the lists of items from the DataFrame column.\n","all_orders = df_wordtovec['extracted_items_list'].tolist()\n","\n","# Create training_sentences from all_orders\n","training_sentences = all_orders # Added this line\n","\n","print(f\"Started with {len(all_orders)} orders.\")\n","print(f\"Training model on {len(training_sentences)} orders with more than one item. ✅\")"]},{"cell_type":"markdown","source":["## 13. Training the Item2Vec Model  \n","\n","With the order data structured as lists of items, we now train a Word2Vec model—adapted here as **Item2Vec**—to learn vector embeddings for each menu item:  \n","\n","1. **Model Parameters**  \n","   - **`vector_size=40`** → Embedding dimension for each item vector.  \n","   - **`window=5`** → Context window size; items within 5 positions in an order are considered related.  \n","   - **`min_count=2`** → Ignores items that appear fewer than 2 times to reduce noise.  \n","   - **`workers=4`** → Uses 4 CPU threads for faster training.  \n","\n","2. **Training Logic**  \n","   - Treats each order as a \"sentence\" and each item as a \"word\".  \n","   - Learns item embeddings based on co-occurrence patterns in orders.  \n","\n","3. **Purpose**  \n","   - Captures semantic similarity between items (e.g., fries and burger vectors may be close).  \n","   - Can power recommendation systems, menu clustering, or basket analysis.  \n","\n","4. **Persistence**  \n","   - Saves the trained model to `item2vec_model.bin` for reuse without retraining.  \n"],"metadata":{"id":"We59C3sQQvw9"}},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8I1WD3MDmeu_","outputId":"ef8eef03-21f8-42d0-a0ca-ef1cf462c53e","executionInfo":{"status":"ok","timestamp":1754936141561,"user_tz":-330,"elapsed":6233,"user":{"displayName":"Abhishek Patil","userId":"16421709600748109372"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Item2Vec model trained successfully. 🚀\n"]}],"source":["## Step 2: Train the Item2Vec Model\n","\n","# This creates and trains your model.\n","# - vector_size: The number of dimensions for the item vector.\n","# - window: The max distance between the current and predicted item in an order.\n","# - min_count: Ignores items with a total frequency lower than this.\n","# - workers: Number of CPU threads to use for training.\n","item2vec_model = Word2Vec(\n","    sentences=training_sentences,\n","    vector_size=40,\n","    window=5,\n","    min_count=2,\n","    workers=4\n",")\n","\n","print(\"\\nItem2Vec model trained successfully. 🚀\")\n","\n","# Optional: Save the model to disk for later use\n","item2vec_model.save(\"item2vec_model.bin\")"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pM3StsChmkSK","outputId":"9e38640a-8558-41b9-bf8b-32ef31f576f3","executionInfo":{"status":"ok","timestamp":1754936141592,"user_tz":-330,"elapsed":18,"user":{"displayName":"Abhishek Patil","userId":"16421709600748109372"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Items most similar to '32 Oz Soda':\n","  - Item: 20 Oz Soda, Similarity Score: 0.5229\n","  - Item: 30 pc Spicy Wings, Similarity Score: 0.4641\n","  - Item: 30 pc Grilled Wings, Similarity Score: 0.4543\n"]}],"source":["## Step 3: How to Use the Trained Model\n","\n","# You can now use the model to find items similar to a given item.\n","# This is perfect for your cold-start recommendation logic.\n","\n","try:\n","    # Let's find items most similar to '32 Oz Soda'\n","    target_item = '32 Oz Soda'\n","    similar_items = item2vec_model.wv.most_similar(target_item, topn=3)\n","\n","    print(f\"\\nItems most similar to '{target_item}':\")\n","    for item, score in similar_items:\n","        print(f\"  - Item: {item}, Similarity Score: {score:.4f}\")\n","\n","except KeyError:\n","    print(f\"\\nItem '{target_item}' not in the model's vocabulary.\")"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"LRADJ_Av6KHJ","executionInfo":{"status":"ok","timestamp":1754936141605,"user_tz":-330,"elapsed":8,"user":{"displayName":"Abhishek Patil","userId":"16421709600748109372"}}},"outputs":[],"source":["from gensim.models import Word2Vec\n","full = Word2Vec.load(\"item2vec_model.bin\")   # load your saved full model\n","full.wv.save(\"item2vec.kv\")                  # save only the keyed vectors for inference\n"]},{"cell_type":"markdown","metadata":{"id":"9X2mfErBmrlz"},"source":["# **FM Data Prparation**"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"id":"hZ8OHzKEmoUa","outputId":"7a2605a0-c3ea-4b43-b854-9eafa172dead","executionInfo":{"status":"ok","timestamp":1754936146394,"user_tz":-330,"elapsed":1700,"user":{"displayName":"Abhishek Patil","userId":"16421709600748109372"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   CUSTOMER_ID  STORE_NUMBER ORDER_CREATED_DATE    ORDER_ID  \\\n","0    362204699          2156         24-07-2024  7247194287   \n","1    269612955          1419         15-02-2025   791214421   \n","2    585330633          2249         15-02-2025  7575285208   \n","3    950661333          2513         29-03-2024  4253875716   \n","4    434985772          1754         08-04-2024  7150407872   \n","\n","  ORDER_CHANNEL_NAME ORDER_SUBCHANNEL_NAME ORDER_OCCASION_NAME  \\\n","0            Digital                   WWT                ToGo   \n","1            Digital                   WWT                ToGo   \n","2            Digital                   WWT                ToGo   \n","3            Digital                   WWT                ToGo   \n","4            Digital                   WWT                ToGo   \n","\n","       CITY_FILLED CUSTOMER_TYPE  \\\n","0        GRAPEVINE    Registered   \n","1     HUNTERSVILLE    Registered   \n","2  Winter Park, FL         Guest   \n","3        LAS VEGAS    Registered   \n","4          ARDMORE         Guest   \n","\n","                                     extracted_items  \n","0  ['10 pc Grilled Wings Combo', '8 pc Grilled Wi...  \n","1  ['Ranch Dip - Regular', '50 pc Grilled Wings',...  \n","2                          ['20pc Spicy Feast Deal']  \n","3     ['20 pc Grilled Wings', 'Ranch Dip - Regular']  \n","4  ['6 pc Grilled Wings Combo', '8 pc Grilled Win...  "],"text/html":["\n","  <div id=\"df-baac4703-bb94-41d4-8917-6830f33e0509\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CUSTOMER_ID</th>\n","      <th>STORE_NUMBER</th>\n","      <th>ORDER_CREATED_DATE</th>\n","      <th>ORDER_ID</th>\n","      <th>ORDER_CHANNEL_NAME</th>\n","      <th>ORDER_SUBCHANNEL_NAME</th>\n","      <th>ORDER_OCCASION_NAME</th>\n","      <th>CITY_FILLED</th>\n","      <th>CUSTOMER_TYPE</th>\n","      <th>extracted_items</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>362204699</td>\n","      <td>2156</td>\n","      <td>24-07-2024</td>\n","      <td>7247194287</td>\n","      <td>Digital</td>\n","      <td>WWT</td>\n","      <td>ToGo</td>\n","      <td>GRAPEVINE</td>\n","      <td>Registered</td>\n","      <td>['10 pc Grilled Wings Combo', '8 pc Grilled Wi...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>269612955</td>\n","      <td>1419</td>\n","      <td>15-02-2025</td>\n","      <td>791214421</td>\n","      <td>Digital</td>\n","      <td>WWT</td>\n","      <td>ToGo</td>\n","      <td>HUNTERSVILLE</td>\n","      <td>Registered</td>\n","      <td>['Ranch Dip - Regular', '50 pc Grilled Wings',...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>585330633</td>\n","      <td>2249</td>\n","      <td>15-02-2025</td>\n","      <td>7575285208</td>\n","      <td>Digital</td>\n","      <td>WWT</td>\n","      <td>ToGo</td>\n","      <td>Winter Park, FL</td>\n","      <td>Guest</td>\n","      <td>['20pc Spicy Feast Deal']</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>950661333</td>\n","      <td>2513</td>\n","      <td>29-03-2024</td>\n","      <td>4253875716</td>\n","      <td>Digital</td>\n","      <td>WWT</td>\n","      <td>ToGo</td>\n","      <td>LAS VEGAS</td>\n","      <td>Registered</td>\n","      <td>['20 pc Grilled Wings', 'Ranch Dip - Regular']</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>434985772</td>\n","      <td>1754</td>\n","      <td>08-04-2024</td>\n","      <td>7150407872</td>\n","      <td>Digital</td>\n","      <td>WWT</td>\n","      <td>ToGo</td>\n","      <td>ARDMORE</td>\n","      <td>Guest</td>\n","      <td>['6 pc Grilled Wings Combo', '8 pc Grilled Win...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-baac4703-bb94-41d4-8917-6830f33e0509')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-baac4703-bb94-41d4-8917-6830f33e0509 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-baac4703-bb94-41d4-8917-6830f33e0509');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-acdbebef-ba72-4135-bed9-879d193723ac\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-acdbebef-ba72-4135-bed9-879d193723ac')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-acdbebef-ba72-4135-bed9-879d193723ac button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"# all_Data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"CUSTOMER_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 266719028,\n        \"min\": 269612955,\n        \"max\": 950661333,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          269612955,\n          434985772,\n          585330633\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"STORE_NUMBER\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 431,\n        \"min\": 1419,\n        \"max\": 2513,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1419,\n          1754,\n          2249\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ORDER_CREATED_DATE\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"15-02-2025\",\n          \"08-04-2024\",\n          \"24-07-2024\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ORDER_ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2905269391,\n        \"min\": 791214421,\n        \"max\": 7575285208,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          791214421,\n          7150407872,\n          7575285208\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ORDER_CHANNEL_NAME\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Digital\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ORDER_SUBCHANNEL_NAME\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"WWT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ORDER_OCCASION_NAME\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"ToGo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CITY_FILLED\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"HUNTERSVILLE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CUSTOMER_TYPE\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Guest\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"extracted_items\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"['Ranch Dip - Regular', '50 pc Grilled Wings', 'Regular Buffalo Fries']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":23}],"source":["all_data = pd.read_csv('final_data.csv')\n","all_data.head()\n","# all_Data.shape\n"]},{"cell_type":"markdown","source":["## 14. Preparing Data for the Factorization Machines (FM) Model  \n","\n","This step reshapes and filters the dataset to create a clean, **customer-item-feature table** suitable for FM-based recommendation modeling:  \n","\n","1. **Convert to Lists**  \n","   - Turns the `extracted_items` string representation into an actual Python list (`extracted_items_list`) for easier manipulation.  \n","\n","2. **Focus on Frequent Customers**  \n","   - Identifies customers with **more than 2 orders** and keeps only their transactions (`df_frequent_customers`).  \n","   - This ensures the FM model has enough interaction data per customer to learn meaningful patterns.  \n","\n","3. **Reshape to Long Format**  \n","   - Uses `explode()` so each item in an order becomes its own row, producing a **transaction-level dataset**.  \n","\n","4. **Clarify Column Names**  \n","   - Renames the exploded item column to `item_name` for better readability.  \n","\n","5. **Select Final Features**  \n","   - Keeps only relevant columns: customer ID, store info, order channels, customer type, and item name.  \n","\n","6. **Handle Missing Values**  \n","   - Replaces any missing entries with `'unknown'` to avoid issues in downstream encoding or modeling.  \n","\n","**Purpose:**  \n","The resulting `fm_data` DataFrame is in a **sparse-friendly format**, ideal for FM models to capture interactions between customers, items, and contextual order features.  \n"],"metadata":{"id":"DpG1LctbQ5YF"}},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OtE3QQn5mw2J","outputId":"a143d657-ace2-4d4d-87b7-68963a10613a","executionInfo":{"status":"ok","timestamp":1754936156905,"user_tz":-330,"elapsed":10582,"user":{"displayName":"Abhishek Patil","userId":"16421709600748109372"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Data prepared for FM model (only customers with > 2 purchases):\n","         CUSTOMER_ID  STORE_NUMBER ORDER_CHANNEL_NAME ORDER_SUBCHANNEL_NAME  \\\n","321436     734312814           857            Digital                   WWT   \n","321437     734312814           857            Digital                   WWT   \n","321437     734312814           857            Digital                   WWT   \n","321438     734312814           857            Digital                   WWT   \n","321439     734312814           857            Digital                   WWT   \n","...              ...           ...                ...                   ...   \n","1012931    991507396          4094            Digital                   WWT   \n","1012932    991507396          4094            Digital                   WWT   \n","1012932    991507396          4094            Digital                   WWT   \n","1012933    991507396          4094            Digital                   WWT   \n","1012933    991507396          4094            Digital                   WWT   \n","\n","        ORDER_OCCASION_NAME CUSTOMER_TYPE                 item_name  \n","321436                 ToGo    Registered  5 pc Crispy Strips Combo  \n","321437                 ToGo    Registered  5 pc Crispy Strips Combo  \n","321437                 ToGo    Registered       Ranch Dip - Regular  \n","321438                 ToGo    Registered  5 pc Crispy Strips Combo  \n","321439                 ToGo    Registered  5 pc Crispy Strips Combo  \n","...                     ...           ...                       ...  \n","1012931                ToGo    Registered     20pc Spicy Feast Deal  \n","1012932                ToGo    Registered     20pc Spicy Feast Deal  \n","1012932                ToGo    Registered       Ranch Dip - Regular  \n","1012933                ToGo    Registered    6 pc Spicy Wings Combo  \n","1012933                ToGo    Registered  6 pc Grilled Wings Combo  \n","\n","[1160955 rows x 7 columns]\n","Data loaded and cleaned successfully.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2092737432.py:34: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  fm_data.fillna('unknown', inplace=True)\n"]}],"source":["# Step 2: Convert the 'extracted_items' string into a real list\n","all_data['extracted_items_list'] = all_data['extracted_items'].apply(ast.literal_eval)\n","\n","# Step 3: Find customers who have appeared more than twice\n","customer_counts = all_data['CUSTOMER_ID'].value_counts()\n","frequent_customer_ids = customer_counts[customer_counts > 2].index\n","\n","# Step 4: Filter the DataFrame to keep only these frequent customers\n","df_frequent_customers = all_data[all_data['CUSTOMER_ID'].isin(frequent_customer_ids)].copy()\n","\n","# Step 5: Transform the data into the \"long\" format\n","df_long = df_frequent_customers.explode('extracted_items_list')\n","\n","# Step 6: Rename the new item column for clarity\n","df_long.rename(columns={'extracted_items_list': 'item_name'}, inplace=True)\n","\n","# Step 7: Select only the final features you need\n","final_features = [\n","    'CUSTOMER_ID',\n","    'STORE_NUMBER',\n","    'ORDER_CHANNEL_NAME',\n","    'ORDER_SUBCHANNEL_NAME',\n","    'ORDER_OCCASION_NAME',\n","    'CUSTOMER_TYPE',\n","    'item_name'\n","]\n","fm_data = df_long[final_features]\n","\n","# --- Display the final result ---\n","print(\"Data prepared for FM model (only customers with > 2 purchases):\")\n","print(fm_data)\n","\n","# --- FIX: Fill any potential missing values ---\n","fm_data.fillna('unknown', inplace=True)\n","\n","print(\"Data loaded and cleaned successfully.\")"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k4LYcGeEmw8a","outputId":"4b2f255a-a466-4529-88e1-a1c7a106eafa","executionInfo":{"status":"ok","timestamp":1754936156997,"user_tz":-330,"elapsed":77,"user":{"displayName":"Abhishek Patil","userId":"16421709600748109372"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Libraries imported successfully.\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import os\n","import ast\n","\n","print(\"Libraries imported successfully.\")"]},{"cell_type":"markdown","source":["## 15. Defining the Upgraded PyTorch Factorization Machine Model & Helper Functions  \n","\n","This cell builds the **PyTorch-based Factorization Machine (FM)** architecture and supporting utilities for training, negative sampling, and early stopping.\n","\n","---\n","\n","### **1. Device Utility**\n","- `get_device()`  \n","  Detects if a CUDA-capable GPU is available; falls back to CPU if not.\n","\n","---\n","\n","### **2. Dataset Class**\n","- `FullFactorizationMachineDataset`  \n","  - Loads a DataFrame with **indexed categorical features** (columns ending in `_idx`) and a label column.\n","  - Returns each sample as:\n","    - **`feature_dict`**: `{feature_name: tensor_of_indices}`\n","    - **`label`**: scalar tensor for binary classification.\n","\n","---\n","\n","### **3. FM Model Architecture**\n","- `FactorizationMachine` class:\n","  - Uses **embedding layers** for each categorical feature to project into a shared vector space of size `k`.\n","  - Computes **pairwise interactions** using the **sum-square trick**:  \n","    \\[\n","    \\frac{1}{2} \\left[ (\\sum V)^2 - \\sum (V^2) \\right]\n","    \\]\n","  - Includes:\n","    - **Bias embeddings per feature**\n","    - **Global bias**\n","    - **Dropout** for regularization\n","  - Weight initialization:\n","    - Embeddings: Normal(0, 0.01)\n","    - Biases: Zero\n","\n","---\n","\n","### **4. Negative Sampling**\n","- `add_negative_samples()`  \n","  - Generates **negative examples** for implicit feedback training.\n","  - For each user:\n","    - Samples `neg_ratio` random items they **have not interacted with**.\n","    - Copies contextual feature values from an existing positive row.\n","\n","---\n","\n","### **5. Training with Early Stopping**\n","- `train_model_with_early_stop()`:\n","  - Implements:\n","    - Mixed Precision Training (`torch.amp`) on GPU\n","    - **Gradient Clipping** (max norm = 1.0)\n","    - **Learning Rate Scheduler** (ReduceLROnPlateau on AUC)\n","    - **Validation AUC** as main metric\n","    - **Early stopping** after `patience` epochs without improvement\n","    - Optional **model checkpoint saving** and reload\n","  - Handles **single-class validation cases** gracefully (AUC = 0.0 if not computable).\n","\n","---\n","\n","**Purpose:**  \n","This upgraded FM setup is capable of modeling **multi-feature categorical data** for recommendations, with built-in regularization, mixed precision for speed, and robust early stopping to avoid overfitting.\n"],"metadata":{"id":"BcBroNavRFP0"}},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oCzDTDymmw-s","outputId":"cb03685f-bc2f-4dd7-eafe-55b90bc55c99","executionInfo":{"status":"ok","timestamp":1754936157022,"user_tz":-330,"elapsed":11,"user":{"displayName":"Abhishek Patil","userId":"16421709600748109372"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","PyTorch classes and functions defined successfully.\n"]}],"source":["# ===================================================================\n","# CELL 4: Define the Upgraded PyTorch Model and Helper Functions\n","# ===================================================================\n","import os\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.metrics import roc_auc_score\n","\n","def get_device():\n","    \"\"\"Checks for CUDA GPU and returns the appropriate torch device.\"\"\"\n","    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","class FullFactorizationMachineDataset(Dataset):\n","    \"\"\"Custom PyTorch Dataset for loading all features.\n","    Expects df to contain columns <feature>_idx for every feature in feature_cols.\n","    \"\"\"\n","    def __init__(self, df, feature_cols, label_col):\n","        # store feature names in the same order passed\n","        self.feature_cols = feature_cols\n","        # Each stored as (N,) torch.long\n","        # Corrected: Access columns using the names provided in feature_cols directly\n","        self.features = {col: torch.tensor(df[col].values, dtype=torch.long) for col in feature_cols}\n","        self.labels = torch.tensor(df[label_col].values, dtype=torch.float32)\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        # Return a dictionary of features (single-index tensors) and the label (scalar tensor)\n","        feature_dict = {col: self.features[col][idx] for col in self.feature_cols}\n","        return feature_dict, self.labels[idx]\n","\n","class FactorizationMachine(nn.Module):\n","    \"\"\"Upgraded Factorization Machine Model to handle multiple categorical features\n","    using the FM sum-square trick. Keeps bias embeddings per feature.\n","    \"\"\"\n","    def __init__(self, num_embeddings_dict, k=64, dropout_p=0.3):\n","        super().__init__()\n","        self.k = k\n","        self.num_embeddings = num_embeddings_dict  # dict: feature -> cardinality\n","\n","        # Embedding for every categorical feature (dim = k)\n","        # NOTE: iteration order of num_embeddings must match the feature order used to create idx columns.\n","        self.feature_embeddings = nn.ModuleDict({\n","            col: nn.Embedding(self.num_embeddings[col], k)\n","            for col in self.num_embeddings\n","        })\n","\n","        # Bias embeddings for every categorical feature\n","        self.biases = nn.ModuleDict({\n","            col: nn.Embedding(self.num_embeddings[col], 1)\n","            for col in self.num_embeddings\n","        })\n","\n","        self.global_bias = nn.Parameter(torch.zeros(1))\n","        self.dropout = nn.Dropout(p=dropout_p)\n","        self._init_weights()\n","\n","    def _init_weights(self):\n","        for emb in self.feature_embeddings.values():\n","            nn.init.normal_(emb.weight, std=0.01)\n","        for emb in self.biases.values():\n","            nn.init.zeros_(emb.weight)\n","\n","    def forward(self, x):\n","        # x: dict of tensors keyed by feature names (each is LongTensor of shape (B,))\n","        # Build list of (B,k) feature vectors in stable order\n","        vecs = [self.dropout(self.feature_embeddings[col](x[col])) for col in self.num_embeddings]\n","\n","        # stack -> (B, F, k)\n","        V = torch.stack(vecs, dim=1)\n","\n","        # FM interaction via sum-square trick:\n","        # summed = sum over features -> (B, k)\n","        summed = V.sum(dim=1)                     # (B, k)\n","        summed_square = (summed * summed).sum(dim=1)  # (B,)\n","        square_sum = (V * V).sum(dim=(1, 2))         # (B,)\n","        interaction = 0.5 * (summed_square - square_sum)  # (B,)\n","\n","        # Biases\n","        batch_size = x[next(iter(self.num_embeddings))].size(0)\n","        total_bias = self.global_bias.expand(batch_size)   # (B,)\n","        for col, emb in self.biases.items():\n","            total_bias = total_bias + emb(x[col]).squeeze(1)\n","\n","        return interaction + total_bias\n","\n","\n","def add_negative_samples(df, num_items, feature_cols, neg_ratio=1):\n","    \"\"\"\n","    Generates negative examples only.\n","    For each user, for each positive item in `df` (train split), sample `neg_ratio` negatives.\n","    Returns a DataFrame with the same feature_idx columns (only negatives).\n","    \"\"\"\n","    user_item_sets = df.groupby('CUSTOMER_ID_idx')['item_name_idx'].apply(set)\n","    neg_samples = []\n","    rng = np.random.default_rng(42)\n","\n","    # feature_cols here should be the names with _idx suffix\n","    feature_cols_with_idx = [col for col in feature_cols if col.endswith('_idx')]\n","    if 'item_name_idx' not in feature_cols_with_idx:\n","         feature_cols_with_idx.append('item_name_idx')\n","\n","\n","    for u_idx, interacted_items in user_item_sets.items():\n","        # pick a representative row for this user to copy context for other features\n","        user_row = df[df['CUSTOMER_ID_idx'] == u_idx].iloc[0]\n","        for pos_item in interacted_items:\n","            for _ in range(neg_ratio):\n","                neg_item_idx = int(rng.integers(0, num_items))\n","                # ensure it's negative\n","                while neg_item_idx in interacted_items:\n","                    neg_item_idx = int(rng.integers(0, num_items))\n","                # Corrected: Copy index columns directly from user_row using their _idx names\n","                neg_sample = {col: user_row[col] for col in feature_cols_with_idx if col != 'item_name_idx'}\n","                neg_sample['item_name_idx'] = neg_item_idx\n","                neg_samples.append(neg_sample)\n","\n","    neg_df = pd.DataFrame(neg_samples)\n","    return neg_df\n","\n","\n","def train_model_with_early_stop(model, train_loader, val_loader, device, optimizer, criterion,\n","                                max_epochs=20, patience=3, model_path=None):\n","    \"\"\"Generic training loop with validation, AMP, LR scheduler, grad clipping and early-stop on val AUC.\n","    Signature unchanged to remain compatible with your code.\n","    \"\"\"\n","    # Scheduler maximizes AUC\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=2, factor=0.5)\n","    scaler = torch.amp.GradScaler('cuda') if device.type == 'cuda' else None\n","\n","    best_val_metric = -float('inf')   # using Val AUC as main metric\n","    epochs_no_improve = 0\n","\n","    for epoch in range(1, max_epochs + 1):\n","        model.train()\n","        total_train_loss = 0.0\n","\n","        for x, l in train_loader:\n","            # x is dict of batched tensors, l is batched labels\n","            x = {k: v.to(device) for k, v in x.items()}\n","            l = l.to(device)\n","            optimizer.zero_grad()\n","\n","            if scaler is not None:\n","                with torch.amp.autocast('cuda'):\n","                    logits = model(x)\n","                    loss = criterion(logits, l)\n","                scaler.scale(loss).backward()\n","                scaler.unscale_(optimizer)\n","                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","                scaler.step(optimizer)\n","                scaler.update()\n","            else:\n","                logits = model(x)\n","                loss = criterion(logits, l)\n","                loss.backward()\n","                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","                optimizer.step()\n","\n","            total_train_loss += loss.item() * l.size(0)\n","\n","        avg_train_loss = total_train_loss / len(train_loader.dataset)\n","\n","        # Validation: compute loss and AUC\n","        model.eval()\n","        total_val_loss = 0.0\n","        all_preds = []\n","        all_labels = []\n","        with torch.no_grad():\n","            for x, l in val_loader:\n","                x = {k: v.to(device) for k, v in x.items()}\n","                l = l.to(device)\n","                if scaler is not None:\n","                    with torch.amp.autocast('cuda'):\n","                        logits = model(x)\n","                        loss = criterion(logits, l)\n","                else:\n","                    logits = model(x)\n","                    loss = criterion(logits, l)\n","\n","                total_val_loss += loss.item() * l.size(0)\n","                preds = torch.sigmoid(logits).detach().cpu().numpy()\n","                all_preds.extend(preds)\n","                all_labels.extend(l.detach().cpu().numpy())\n","\n","        avg_val_loss = total_val_loss / len(val_loader.dataset)\n","\n","        # Safely compute AUC (guard in case single-class)\n","        try:\n","            val_auc = roc_auc_score(all_labels, all_preds)\n","        except Exception:\n","            val_auc = 0.0\n","\n","        print(f\"[FM] Epoch {epoch:02d}: Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}, Val AUC: {val_auc:.6f}\")\n","\n","        # Scheduler step (maximize AUC)\n","        scheduler.step(val_auc)\n","\n","        # Early stopping based on val AUC\n","        if val_auc > best_val_metric:\n","            best_val_metric = val_auc\n","            epochs_no_improve = 0\n","            if model_path:\n","                try:\n","                    torch.save(model.state_dict(), model_path)\n","                except Exception as e:\n","                    print(f\"Warning: couldn't save checkpoint to {model_path}: {e}\")\n","        else:\n","            epochs_no_improve += 1\n","\n","        if epochs_no_improve >= patience:\n","            print(f\"[FM] Early stopping after {patience} epochs (no improvement on val AUC).\")\n","            break\n","\n","    # Try-safe load of best model (avoid crash if checkpoint incompatible)\n","    if model_path and os.path.exists(model_path):\n","        try:\n","            sd = torch.load(model_path, map_location=device)\n","            model.load_state_dict(sd)\n","        except Exception as e:\n","            print(f\"Warning: unable to load saved model from {model_path}: {e}. Keeping current model weights.\")\n","    return model\n","\n","print(\"\\nPyTorch classes and functions defined successfully.\")"]},{"cell_type":"markdown","source":["## 16. Creating Datasets & Training the Factorization Machine Model\n","\n","This cell prepares **encoded categorical data**, generates negative samples, and trains the **PyTorch Factorization Machine (FM)** with early stopping.\n","\n","---\n","\n","### 1. Label Assignment\n","- Adds a **positive label (`1.0`)** for all observed interactions.\n","\n","---\n","\n","### 2. Feature Encoding\n","- Uses **`LabelEncoder`** to map each categorical column to integer IDs (`_idx` suffix).\n","- Stores the **vocabulary size** per feature in `num_embeddings` for FM embedding layers.\n","\n","---\n","\n","### 3. Train/Validation Split\n","- **`train_test_split`** with stratification on `CUSTOMER_ID_idx` ensures balanced user distribution in both sets.\n","\n","---\n","\n","### 4. Negative Sampling\n","- `add_negative_samples()` creates **synthetic negative interactions**:\n","  - Same contextual features\n","  - Random unseen items per user\n","- Done for **both** training and validation sets for binary classification.\n","\n","---\n","\n","### 5. Final Dataset Assembly\n","- Concatenates **positive** and **negative** samples.\n","- Shuffles to avoid ordering bias.\n","\n","---\n","\n","### 6. DataLoader Creation\n","- Wraps the data in **`FullFactorizationMachineDataset`** for PyTorch.\n","- Uses **large batch size (4096)** with pinned memory for speed.\n","\n","---\n","\n","### 7. Model Setup & Training\n","- Initializes `FactorizationMachine` with:\n","  - `k=50` latent dimensions\n","  - `dropout_p=0.3`\n","- Optimizer: **AdamW** with weight decay  \n","- Loss: **Binary Cross-Entropy with Logits**\n","- Trains via `train_model_with_early_stop()`:\n","  - Mixed Precision (`torch.amp`)\n","  - Learning Rate Scheduler\n","  - Early stopping on **validation AUC**\n","  - Saves best model checkpoint (`best_fm_model.pth`)\n","\n","---\n","\n","**Purpose:**  \n","Generates **balanced train/validation datasets** and runs **robust FM training** with regularization, negative sampling, and early stopping for recommendation modeling.\n"],"metadata":{"id":"aatMJgC8RtHB"}},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tKE8lkhWmxCE","outputId":"6a131067-251c-4ff2-ed11-b452b5d02274","executionInfo":{"status":"ok","timestamp":1754936823428,"user_tz":-330,"elapsed":665716,"user":{"displayName":"Abhishek Patil","userId":"16421709600748109372"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1426253410.py:10: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  fm_data['label'] = 1.0\n","/tmp/ipython-input-1426253410.py:19: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  fm_data[f'{col}_idx'] = le.fit_transform(fm_data[col])\n","/tmp/ipython-input-1426253410.py:19: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  fm_data[f'{col}_idx'] = le.fit_transform(fm_data[col])\n"]},{"output_type":"stream","name":"stdout","text":["\n","Starting training on device: cuda\n","Batch size: 4096\n","Model param count: 4,596,478\n","[FM] Epoch 01: Train Loss: 0.528471, Val Loss: 0.503099, Val AUC: 0.883822\n","[FM] Epoch 02: Train Loss: 0.399049, Val Loss: 0.443062, Val AUC: 0.885986\n","[FM] Epoch 03: Train Loss: 0.371962, Val Loss: 0.431886, Val AUC: 0.886541\n","[FM] Epoch 04: Train Loss: 0.363437, Val Loss: 0.427992, Val AUC: 0.886611\n","[FM] Epoch 05: Train Loss: 0.358932, Val Loss: 0.427671, Val AUC: 0.886351\n","[FM] Epoch 06: Train Loss: 0.355908, Val Loss: 0.426090, Val AUC: 0.886022\n","[FM] Epoch 07: Train Loss: 0.352749, Val Loss: 0.428492, Val AUC: 0.885835\n","[FM] Early stopping after 3 epochs (no improvement on val AUC).\n","\n","Model training complete! 🚀 Best model saved to 'best_fm_model.pth' (if saving succeeded).\n"]}],"source":["# ===================================================================\n","# CELL 5: Create Datasets and Train the Model\n","# ===================================================================\n","import os\n","import torch.optim as optim\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","# 1. Add positive labels to the data (if not already)\n","fm_data['label'] = 1.0\n","\n","# 2. Encode categorical features and create _idx columns\n","categorical_features = ['CUSTOMER_ID', 'STORE_NUMBER', 'ORDER_CHANNEL_NAME', 'ORDER_SUBCHANNEL_NAME', 'ORDER_OCCASION_NAME', 'CUSTOMER_TYPE', 'item_name']\n","num_embeddings = {}\n","feature_columns = [] # To store the names of the _idx columns\n","\n","for col in categorical_features:\n","    le = LabelEncoder()\n","    fm_data[f'{col}_idx'] = le.fit_transform(fm_data[col])\n","    num_embeddings[f'{col}_idx'] = len(le.classes_)\n","    feature_columns.append(f'{col}_idx')\n","\n","# 3. Split data into training and validation sets\n","# Keep stratify by user for balanced user representation in val\n","train_df, val_df = train_test_split(\n","    fm_data,\n","    test_size=0.2,\n","    random_state=42,\n","    stratify=fm_data['CUSTOMER_ID_idx']\n",")\n","\n","# --- Create negatives for training and for validation so both classes exist in val ---\n","neg_df = add_negative_samples(train_df, num_embeddings['item_name_idx'], feature_columns, neg_ratio=1)\n","neg_df['label'] = 0.0\n","\n","val_neg_df = add_negative_samples(val_df, num_embeddings['item_name_idx'], feature_columns, neg_ratio=1)\n","val_neg_df['label'] = 0.0\n","\n","# 4. Combine positive (train_df) and negative (neg_df) samples for final training set\n","final_train_df = pd.concat([train_df, neg_df]).sample(frac=1, random_state=42).reset_index(drop=True)\n","final_val_df = pd.concat([val_df, val_neg_df]).sample(frac=1, random_state=42).reset_index(drop=True)\n","\n","# 5. Create PyTorch Datasets and DataLoaders\n","batch_size = 4096  # increase if GPU memory allows; reduce if OOM\n","train_dataset = FullFactorizationMachineDataset(final_train_df, feature_columns, 'label')\n","val_dataset = FullFactorizationMachineDataset(final_val_df, feature_columns, 'label')\n","\n","# use num_workers=2 to avoid the worker warnings/freezes on some systems\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n","\n","# Optional: remove old incompatible checkpoint to avoid load conflicts\n","if os.path.exists(\"best_fm_model.pth\"):\n","    try:\n","        os.remove(\"best_fm_model.pth\")\n","        print(\"Removed existing checkpoint best_fm_model.pth to avoid state_dict mismatches.\")\n","    except Exception as e:\n","        print(f\"Could not remove old checkpoint: {e}\")\n","\n","\n","# 6. Initialize model, optimizer, and loss function\n","device = get_device()\n","model = FactorizationMachine(num_embeddings, k=50, dropout_p=0.3).to(device)\n","optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n","criterion = nn.BCEWithLogitsLoss()\n","\n","print(f\"\\nStarting training on device: {device}\\nBatch size: {batch_size}\\nModel param count: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n","\n","# 7. Train the model (early-stop + AMP + scheduler inside)\n","trained_model = train_model_with_early_stop(\n","    model, train_loader, val_loader, device, optimizer, criterion,\n","    max_epochs=30, patience=3, model_path=\"best_fm_model.pth\"\n",")\n","\n","print(\"\\nModel training complete! 🚀 Best model saved to 'best_fm_model.pth' (if saving succeeded).\")"]},{"cell_type":"markdown","source":["## Parsing & Analyzing Extracted Items\n","\n","This section:\n","- Parses the `extracted_items` column into clean Python lists.\n","- Explodes the lists into individual rows for normalization.\n","- Counts item frequencies and identifies the top 20 most common items.\n","- Adds each item's percentage share of all extracted items.\n"],"metadata":{"id":"w0xJ0XhOTydw"}},{"cell_type":"code","execution_count":28,"metadata":{"id":"9GiKCDtnrsWy","executionInfo":{"status":"ok","timestamp":1754936837951,"user_tz":-330,"elapsed":14539,"user":{"displayName":"Abhishek Patil","userId":"16421709600748109372"}}},"outputs":[],"source":["import ast\n","import pandas as pd\n","\n","# load (if not already loaded)\n","all_data = pd.read_csv('final_data.csv')\n","\n","def parse_items(x):\n","    \"\"\"Return a list of items from different possible formats.\"\"\"\n","    if pd.isna(x):\n","        return []\n","    if isinstance(x, (list, tuple, set)):\n","        return list(x)\n","    # try parse python literal like \"['a','b']\"\n","    try:\n","        val = ast.literal_eval(x)\n","        if isinstance(val, (list, tuple, set)):\n","            return list(val)\n","        # if literal_eval gives a single string, fall through to splitting\n","    except Exception:\n","        pass\n","    # fallback: split on comma and strip whitespace\n","    return [s.strip() for s in str(x).split(',') if s.strip()]\n","\n","# create parsed list column\n","all_data['items_list'] = all_data['extracted_items'].apply(parse_items)\n","\n","# explode and normalize (optional: lower() to merge case variants)\n","exploded = all_data.explode('items_list')\n","exploded['items_list'] = exploded['items_list'].astype(str).str.strip()\n","\n","# remove empty strings that may appear\n","exploded = exploded[exploded['items_list'] != '']\n","\n","# get frequency counts and top 20\n","item_counts = exploded['items_list'].value_counts()\n","top20 = item_counts.head(20)\n","\n","# as a dataframe\n","top20_df = top20.reset_index().rename(columns={'index': 'item'})\n","\n","# Convert 'count' column to numeric\n","top20_df['count'] = pd.to_numeric(top20_df['count'])\n","\n","# add percentage of total items (optional)\n","total_items = exploded['items_list'].shape[0]\n","top20_df['pct_of_items'] = (top20_df['count'] / total_items * 100).round(2)"]},{"cell_type":"markdown","source":["# Fast, Practical Hybrid Recommender\n","\n","## Core Idea\n","A **hybrid recommender** that builds recommendations by cheaply scoring a fixed candidate pool with two fast signals — **item2vec cosine similarity** and **normalized item popularity** — then optionally refines the top candidates per user with a heavier **Factorization Machine (FM)**.  \n","Finally, it blends these signals using **simple, customer-frequency–bucketed weights** to produce **top-N picks**.\n","\n","---\n","\n","## What It Does (Big Picture)\n","\n","1. **Candidate Pool & Popularity**\n","   - Candidates come from encoder classes.\n","   - Popularity = `item_count / total_items`, normalized to **[0, 1]**.\n","\n","2. **Item2vec Precompute**\n","   - Load gensim vectors.\n","   - Build:\n","     - `candidate_w2v_matrix`\n","     - Per-candidate norms\n","     - Mask for missing vectors\n","\n","3. **User Vectors (Fast)**\n","   - Compute mean vector of recent items (`item1`–`item3`) per row.\n","   - Compute **all candidates × all users** cosine similarities via:\n","     - One matrix multiplication\n","     - Elementwise division\n","   - Map to **[0, 1]** → `sims_mat` (the high-throughput core).\n","\n","4. **Shortlist + FM (Optional)**\n","   - Use a cheap prefilter (weighted w2v + pop) to pick **top-K** candidates per user.\n","   - Run trained **FM** on this shortlist (in chunks) to get fine-grained probabilities.\n","   - Normalize per row and insert back into a full-length FM score vector.\n","\n","5. **Blend & Output**\n","   - Combine:\n","     - `fm_score`\n","     - `w2v_score`\n","     - `pop_score`\n","   - Use weights from `WEIGHTS` depending on **customer frequency bucket**:\n","     - `new`\n","     - `mid`\n","     - `freq`\n","   - Take **top-3** results.\n","\n","---\n","\n","## Why This Pattern Works\n","\n","- **Speed**  \n","  - Vectorized BLAS operations for embeddings are much faster than looping model inference.  \n","  - Running FM only on shortlists saves expensive compute.\n","\n","- **Robustness**  \n","  - Falls back gracefully if item2vec or FM data is missing.\n","\n","- **Control**  \n","  - Bucketed weights give interpretable, low-risk control over personalization vs popularity.\n","\n","---\n","\n","## Normalization & Safety\n","\n","- Cosine similarities and popularity are normalized to be comparable.\n","- FM outputs are sigmoid probabilities.\n","- Zeros in norms and missing vectors:\n","  - Masked (low similarity)\n","  - Prevents division errors or promotion of unrepresented items.\n","\n","---\n","\n","## Performance & Scaling\n","\n","- **Memory/Time Complexity:**  \n","  - Dense similarity matrix = `O(n_candidates × n_rows × dim)`.  \n","  - For large workloads:\n","    - Use per-user ANN (e.g., FAISS) for top candidates.\n","    - Stream rows in batches.\n","\n","- **Tuning Trade-offs:**\n","  - Adjust `TOP_CAND_POP`, `TOP_K_FM`, and `WEIGHTS` to balance accuracy vs latency.\n","\n","---\n","\n","## Practical Tuning & Evaluation\n","\n","- **Offline Metrics:**\n","  - Recall@K\n","  - NDCG@K\n","  - MRR\n","\n","- **A/B Testing** for live validation.\n","\n","- Search weights on validation set or:\n","  - Train a small meta-learner to replace hard weights for better calibration.\n"],"metadata":{"id":"P2Mb8FVCTepW"}},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vnN8q9yKTl6A","outputId":"0bb0f58c-25d6-42b2-9d80-cbb9bf8ead4a","executionInfo":{"status":"ok","timestamp":1754937449322,"user_tz":-330,"elapsed":170025,"user":{"displayName":"Abhishek Patil","userId":"16421709600748109372"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded KeyedVectors from /content/item2vec.kv (vocab 126)\n","Precomputed candidate_w2v_matrix: (129, 40)\n","Loaded FM checkpoint.\n","Test rows: 1000, Candidates: 129\n","W2V vectorized precompute done in 0.05s\n"]},{"output_type":"stream","name":"stderr","text":["Scoring test rows: 100%|██████████| 1000/1000 [02:45<00:00,  6.04it/s]"]},{"output_type":"stream","name":"stdout","text":["Saved recommendations to recommendations.csv — completed in 165.64s\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# ---------- Fast, drop-in replacement (copy-paste this whole cell) ----------\n","import os, ast, time\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","\n","# optional libs used by original script (Colab usually has them)\n","import torch\n","from gensim.models import KeyedVectors, Word2Vec\n","from sklearn.preprocessing import LabelEncoder\n","\n","# ---------- Config / weights (tweak these) ----------\n","WEIGHTS = {\n","    'new':  {'fm': 0.0, 'w2v': 0.8, 'pop': 0.2},\n","    'mid':  {'fm': 0.2, 'w2v': 0.5, 'pop': 0.3},\n","    'freq': {'fm': 0.6, 'w2v': 0.3, 'pop': 0.1},\n","}\n","TOP_CAND_POP = 2000        # candidate pool size (same as your earlier setting)\n","TOP_K_FM = 400             # number of candidates to run FM on per row (speed / fidelity tradeoff)\n","\n","# file names (adjust if needed)\n","file_path = '/content/drive/MyDrive/Colab Notebooks/WWT Hackathon/content/Dataset/'   # change if your csvs are elsewhere\n","TEST_FILE = file_path + 'test_data_question.csv'\n","FINAL_DATA_FILE = 'final_data.csv'   # assumed in WORKING DIR, change if needed\n","ITEM2VEC_FILE = \"/content/item2vec.kv\"   # your provided .kv path in Colab\n","FM_CHECKPOINT = 'best_fm_model.pth'\n","OUT_FILE = 'recommendations.csv'\n","\n","# ---------- Helpers ----------\n","def parse_items_col(x):\n","    if pd.isna(x): return []\n","    if isinstance(x, (list, tuple, set)): return list(x)\n","    try:\n","        v = ast.literal_eval(x)\n","        if isinstance(v, (list, tuple, set)): return list(v)\n","    except Exception:\n","        pass\n","    return [s.strip() for s in str(x).split(',') if s.strip()]\n","\n","def safe_label_encode(enc, val):\n","    try:\n","        return int(enc.transform([val])[0])\n","    except Exception:\n","        try:\n","            if 'unknown' in enc.classes_:\n","                return int(enc.transform(['unknown'])[0])\n","        except Exception:\n","            pass\n","        return int(0)\n","\n","def normalize_array(arr):\n","    arr = np.array(arr, dtype=float)\n","    mn, mx = arr.min(), arr.max()\n","    if mx - mn < 1e-12:\n","        return np.zeros_like(arr)\n","    return (arr - mn) / (mx - mn)\n","\n","def _get_val_from_row(row, col):\n","    if isinstance(row, dict):\n","        return row.get(col, None)\n","    else:\n","        return getattr(row, col, None)\n","\n","# gensim compatibility helpers\n","def kv_has(kv, key):\n","    if key is None or (isinstance(key, float) and np.isnan(key)):\n","        return False\n","    try:\n","        return key in kv.key_to_index\n","    except Exception:\n","        try:\n","            return key in kv.vocab\n","        except Exception:\n","            try:\n","                return key in kv.index_to_key\n","            except Exception:\n","                return False\n","\n","def kv_get_vector(kv, key):\n","    try:\n","        return kv.get_vector(key)\n","    except Exception:\n","        try:\n","            return kv[key]\n","        except Exception:\n","            try:\n","                return kv.wv[key]\n","            except Exception:\n","                raise KeyError(f\"Key {key} not found in kv\")\n","\n","# ---------- 1. Load training data / items ----------\n","if 'all_data' not in globals():\n","    if os.path.exists(FINAL_DATA_FILE):\n","        all_data = pd.read_csv(FINAL_DATA_FILE)\n","    elif os.path.exists(os.path.join(file_path, FINAL_DATA_FILE)):\n","        all_data = pd.read_csv(os.path.join(file_path, FINAL_DATA_FILE))\n","    else:\n","        raise FileNotFoundError(f\"Could not find {FINAL_DATA_FILE} in cwd or {file_path}\")\n","\n","if 'items_list' not in all_data.columns:\n","    all_data['items_list'] = all_data['extracted_items'].apply(parse_items_col)\n","\n","# popularity\n","exploded = all_data.explode('items_list')\n","exploded['items_list'] = exploded['items_list'].astype(str).str.strip()\n","exploded = exploded[exploded['items_list'] != '']\n","item_counts = exploded['items_list'].value_counts()\n","total_items = item_counts.sum()\n","pop_score = (item_counts / (total_items + 1e-12)).to_dict()\n","\n","# ---------- 2. Customer frequency ----------\n","cust_counts_map = all_data['CUSTOMER_ID'].value_counts().to_dict()\n","\n","# ---------- 3. Encoders & candidate list ----------\n","feature_columns = ['CUSTOMER_ID', 'STORE_NUMBER', 'ORDER_CHANNEL_NAME',\n","                   'ORDER_SUBCHANNEL_NAME', 'ORDER_OCCASION_NAME', 'CUSTOMER_TYPE', 'item_name']\n","\n","if ('encoders' not in globals()) or ('feature_columns' not in globals()):\n","    tmp_df = all_data.copy().explode('items_list').rename(columns={'items_list': 'item_name'})\n","    fm_data_tmp = tmp_df[feature_columns].fillna('unknown').astype(str)\n","    encoders = {}\n","    num_embeddings = {}\n","    for col in feature_columns:\n","        enc = LabelEncoder()\n","        enc.fit(fm_data_tmp[col].astype(str).values)\n","        encoders[col] = enc\n","        num_embeddings[col] = len(enc.classes_)\n","    print(\"Recreated encoders from all_data (fallback).\")\n","\n","candidate_items_all = list(encoders['item_name'].classes_)\n","candidate_pop_scores = [pop_score.get(it, 0.0) for it in candidate_items_all]\n","cands_df = pd.DataFrame({'item': candidate_items_all, 'pop': candidate_pop_scores})\n","cands_df = cands_df.sort_values('pop', ascending=False).reset_index(drop=True)\n","candidate_list = cands_df['item'].tolist()[:TOP_CAND_POP]\n","\n","candidate_pop_array = np.array([pop_score.get(it, 0.0) for it in candidate_list], dtype=float)\n","if candidate_pop_array.max() > 0:\n","    candidate_pop_array = normalize_array(candidate_pop_array)\n","else:\n","    candidate_pop_array = np.zeros_like(candidate_pop_array)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","candidate_item_idxs = []\n","for it in candidate_list:\n","    candidate_item_idxs.append(safe_label_encode(encoders['item_name'], it))\n","candidate_item_idxs = torch.tensor(candidate_item_idxs, dtype=torch.long, device=device)\n","\n","# ---------- 4. Load item2vec & precompute candidate W2V matrix ----------\n","item2vec = None\n","candidate_w2v_matrix = None\n","candidate_w2v_mask = None\n","candidate_w2v_norms = None\n","vsize = None\n","\n","if os.path.exists(ITEM2VEC_FILE):\n","    try:\n","        item2vec = KeyedVectors.load(ITEM2VEC_FILE, mmap='r')\n","        print(f\"Loaded KeyedVectors from {ITEM2VEC_FILE} (vocab {len(item2vec.key_to_index)})\")\n","    except Exception:\n","        try:\n","            w2v = Word2Vec.load(ITEM2VEC_FILE)\n","            item2vec = w2v.wv\n","            print(\"Loaded Word2Vec and using .wv\")\n","        except Exception:\n","            try:\n","                item2vec = KeyedVectors.load_word2vec_format(ITEM2VEC_FILE, binary=True)\n","                print(\"Loaded word2vec-format binary\")\n","            except Exception as e:\n","                print(\"Failed to load item2vec:\", e)\n","                item2vec = None\n","else:\n","    print(\"Warning: item2vec file not found:\", ITEM2VEC_FILE)\n","\n","if item2vec is not None:\n","    try:\n","        vsize = item2vec.vector_size\n","    except Exception:\n","        try:\n","            vsize = item2vec.vectors.shape[1]\n","        except Exception:\n","            raise RuntimeError(\"Can't determine vector size from item2vec object\")\n","\n","    vecs = []\n","    mask = []\n","    for it in candidate_list:\n","        if kv_has(item2vec, it):\n","            v = kv_get_vector(item2vec, it).astype(np.float32)\n","            vecs.append(v)\n","            mask.append(1)\n","        else:\n","            vecs.append(np.zeros(vsize, dtype=np.float32))\n","            mask.append(0)\n","    candidate_w2v_matrix = np.vstack(vecs) if len(vecs) > 0 else None\n","    candidate_w2v_norms = (np.linalg.norm(candidate_w2v_matrix, axis=1) if candidate_w2v_matrix is not None else None)\n","    if candidate_w2v_norms is not None:\n","        candidate_w2v_norms = np.where(candidate_w2v_norms == 0.0, 1.0, candidate_w2v_norms)\n","    candidate_w2v_mask = np.array(mask, dtype=bool)\n","    print(\"Precomputed candidate_w2v_matrix:\", None if candidate_w2v_matrix is None else candidate_w2v_matrix.shape)\n","else:\n","    candidate_w2v_matrix = None\n","    candidate_w2v_mask = None\n","    candidate_w2v_norms = None\n","\n","# ---------- 5. Load FM model ----------\n","fm_model = None\n","if os.path.exists(FM_CHECKPOINT):\n","    try:\n","        if 'FactorizationMachine' in globals():\n","            fm_model = FactorizationMachine(num_embeddings, k=50, dropout_p=0.0).to(device)\n","            sd = torch.load(FM_CHECKPOINT, map_location=device)\n","            fm_model.load_state_dict(sd, strict=False)\n","            fm_model.eval()\n","            print(\"Loaded FM checkpoint.\")\n","        else:\n","            print(\"FactorizationMachine class not found; FM skipped.\")\n","            fm_model = None\n","    except Exception as e:\n","        print(\"Warning: Could not load FM model:\", e)\n","        fm_model = None\n","else:\n","    print(\"FM checkpoint not found; FM scoring will be skipped.\")\n","    fm_model = None\n","\n","# ---------- 6. Read test file ----------\n","if os.path.exists(TEST_FILE):\n","    test_df = pd.read_csv(TEST_FILE, sep=None, engine='python')\n","elif os.path.exists(os.path.join(file_path, os.path.basename(TEST_FILE))):\n","    test_df = pd.read_csv(os.path.join(file_path, os.path.basename(TEST_FILE)), sep=None, engine='python')\n","else:\n","    raise FileNotFoundError(f\"Could not find test file {TEST_FILE}\")\n","\n","expected_cols = ['CUSTOMER_ID','STORE_NUMBER','ORDER_CHANNEL_NAME','ORDER_SUBCHANNEL_NAME',\n","                 'ORDER_OCCASION_NAME','CUSTOMER_TYPE','item1','item2','item3']\n","for col in expected_cols:\n","    if col not in test_df.columns:\n","        test_df[col] = np.nan\n","\n","n_rows = len(test_df)\n","print(f\"Test rows: {n_rows}, Candidates: {len(candidate_list)}\")\n","\n","# ---------- 7. Vectorized W2V: build user vectors ----------\n","start_time = time.time()\n","if (item2vec is not None) and (candidate_w2v_matrix is not None):\n","    recent_items_per_row = []\n","    for row in test_df.itertuples(index=False):\n","        recent = []\n","        for c in ['item1', 'item2', 'item3']:\n","            v = getattr(row, c, None)\n","            if pd.isna(v) or v is None:\n","                continue\n","            vs = str(v).strip()\n","            if vs == '':\n","                continue\n","            if ',' in vs:\n","                vs = vs.split(',')[0].strip()\n","            if kv_has(item2vec, vs):\n","                recent.append(vs)\n","        recent_items_per_row.append(recent)\n","\n","    user_vectors = np.zeros((n_rows, vsize), dtype=np.float32)\n","    user_norms = np.zeros((n_rows,), dtype=np.float32)\n","    for i, recent in enumerate(recent_items_per_row):\n","        if len(recent) == 0:\n","            continue\n","        vecs = [kv_get_vector(item2vec, it).astype(np.float32) for it in recent]\n","        mean_vec = np.mean(vecs, axis=0)\n","        norm = np.linalg.norm(mean_vec)\n","        user_vectors[i] = mean_vec\n","        user_norms[i] = norm if norm > 0 else 0.0\n","\n","    user_norms_safe = user_norms.copy()\n","    user_norms_safe[user_norms_safe == 0.0] = 1.0\n","    denom = np.outer(candidate_w2v_norms, user_norms_safe)\n","    nums = candidate_w2v_matrix.dot(user_vectors.T)\n","    sims_mat = np.divide(nums, denom, out=np.full_like(nums, -1.0), where=(denom != 0.0))\n","    zero_user_mask = (user_norms == 0.0)\n","    if zero_user_mask.any():\n","        sims_mat[:, zero_user_mask] = -1.0\n","    if candidate_w2v_mask is not None:\n","        sims_mat[~candidate_w2v_mask, :] = -1.0\n","    sims_mat = (sims_mat + 1.0) / 2.0\n","    sims_mat = np.clip(sims_mat, 0.0, 1.0)\n","else:\n","    sims_mat = np.zeros((len(candidate_list), n_rows), dtype=float)\n","    recent_items_per_row = [[] for _ in range(n_rows)]\n","    user_vectors = np.zeros((n_rows, 1), dtype=float)\n","    user_norms = np.zeros((n_rows,), dtype=float)\n","\n","print(\"W2V vectorized precompute done in {:.2f}s\".format(time.time() - start_time))\n","\n","# ---------- helper: FM scoring ----------\n","def score_fm_subset_for_row(row, candidate_idxs_tensor_subset, chunk_size=512):\n","    if fm_model is None:\n","        return np.zeros(candidate_idxs_tensor_subset.shape[0], dtype=float)\n","    B = candidate_idxs_tensor_subset.shape[0]\n","    out_probs = np.zeros(B, dtype=float)\n","    encoded_cols = {}\n","    for col in feature_columns:\n","        if col == 'item_name':\n","            continue\n","        val = _get_val_from_row(row, col)\n","        if pd.isna(val) or val is None:\n","            val = 'unknown'\n","        encoded_cols[col] = safe_label_encode(encoders[col], str(val))\n","    start = 0\n","    while start < B:\n","        end = min(start + chunk_size, B)\n","        size = end - start\n","        batch = {}\n","        batch['item_name'] = candidate_idxs_tensor_subset[start:end]\n","        for col in feature_columns:\n","            if col == 'item_name': continue\n","            idx_val = encoded_cols[col]\n","            batch[col] = torch.full((size,), idx_val, dtype=torch.long, device=device)\n","        with torch.no_grad():\n","            logits = fm_model(batch)\n","            if isinstance(logits, torch.Tensor):\n","                probs = torch.sigmoid(logits).detach().cpu().numpy().ravel()\n","            else:\n","                logits_arr = np.array(logits)\n","                probs = 1.0 / (1.0 + np.exp(-logits_arr)).ravel()\n","        out_probs[start:end] = probs\n","        start = end\n","    return out_probs\n","\n","# ---------- 8. Compose final recommendations ----------\n","rows_out = []\n","start = time.time()\n","ncands = len(candidate_list)\n","pop_norm_vector = candidate_pop_array\n","\n","for ridx, row in enumerate(tqdm(test_df.itertuples(index=False), total=n_rows, desc=\"Scoring test rows\")):\n","    cid = getattr(row, 'CUSTOMER_ID', None)\n","    sn = getattr(row, 'STORE_NUMBER', None)\n","    oid = getattr(row, 'ORDER_ID', None)\n","    ocn = getattr(row,'ORDER_CHANNEL_NAME', None)\n","    osn = getattr(row, 'ORDER_SUBCHANNEL_NAME', None)\n","    oon = getattr(row, 'ORDER_OCCASION_NAME', None)\n","    ct = getattr(row, 'CUSTOMER_TYPE', None)\n","    it1 = getattr(row, 'item1', None)\n","    it2 = getattr(row, 'item2', None)\n","    it3 = getattr(row, 'item3', None)\n","    it4 = None\n","\n","    freq = int(cust_counts_map.get(cid, 0))\n","    if freq <= 1:\n","        bucket = 'new'\n","    elif 2 <= freq <= 4:\n","        bucket = 'mid'\n","    else:\n","        bucket = 'freq'\n","    w = WEIGHTS[bucket]\n","\n","    w2v_scores = sims_mat[:, ridx]\n","    pop_scores = pop_norm_vector.copy()\n","\n","    fm_scores_full = np.zeros(ncands, dtype=float)\n","    if (w['fm'] > 0.0) and (fm_model is not None):\n","        prefilter_score = (w['w2v'] * w2v_scores) + (w['pop'] * pop_scores)\n","        K = min(max(50, TOP_K_FM), ncands)\n","        if K < ncands:\n","            topK_idx = np.argpartition(-prefilter_score, K-1)[:K]\n","            topK_idx = topK_idx[np.argsort(-prefilter_score[topK_idx])]\n","        else:\n","            topK_idx = np.arange(ncands, dtype=int)\n","        cand_idxs_subset = candidate_item_idxs[topK_idx]\n","        fm_subset_probs = score_fm_subset_for_row(row, cand_idxs_subset)\n","        if fm_subset_probs.max() - fm_subset_probs.min() > 1e-9:\n","            fm_subset_norm = normalize_array(fm_subset_probs)\n","        else:\n","            fm_subset_norm = fm_subset_probs.copy()\n","        fm_scores_full[topK_idx] = fm_subset_norm\n","    else:\n","        fm_scores_full = np.zeros(ncands, dtype=float)\n","\n","    combined = w['fm'] * fm_scores_full + w['w2v'] * np.clip(w2v_scores, 0.0, 1.0) + w['pop'] * np.clip(pop_scores, 0.0, 1.0)\n","\n","    top_idx = np.argsort(-combined)[:3]\n","    recs = [candidate_list[i] for i in top_idx]\n","    rec_scores = [float(combined[i]) for i in top_idx]\n","\n","    rows_out.append({\n","        'CUSTOMER_ID': cid,\n","        'STORE_NUMBER': sn,\n","        'ORDER_ID': oid,\n","        'ORDER_CHANNEL_NAME': ocn,\n","        'ORDER_SUBCHANNEL_NAME': osn,\n","        'ORDER_OCCASION_NAME': oon,\n","        'CUSTOMER_TYPE': ct,\n","        'item1': it1,\n","        'item2': it2,\n","        'item3': it3,\n","        'it4': it4,\n","        'RECOMMENDATION 1': recs[0] if len(recs) > 0 else None,\n","        'rec_2': recs[1] if len(recs) > 1 else None,\n","        'rec_3': recs[2] if len(recs) > 2 else None,\n","    })\n","\n","elapsed = time.time() - start\n","out_df = pd.DataFrame(rows_out)\n","out_df.to_csv(OUT_FILE, index=False)\n","print(f\"Saved recommendations to {OUT_FILE} — completed in {elapsed:.2f}s\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WgmKFS2jaz4q"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}